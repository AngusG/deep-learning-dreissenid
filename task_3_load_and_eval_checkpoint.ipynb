{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "#import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/scratch/ssd/cciw/dataset_voc/'\n",
    "file = '1349_2016-07-06_2_GLN_3061_crop'\n",
    "\n",
    "label_path = os.path.join(os.path.join(path, 'SegmentationClassPNG'), file)\n",
    "image_path = os.path.join(os.path.join(path, 'JPEGImages'), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for debugging purposes\n",
    "# dlpath = '/scratch/gallowaa/'\n",
    "# trainset = ds.VOCSegmentation(dlpath, image_set='val', download=True, transform=transform)\n",
    "trainset = datasets.VOCSegmentation(\n",
    "    root='/scratch/ssd/cciw/', year='2012', image_set='train',\n",
    "    download=False, transform=transform, target_transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs, targets in trainloader:\n",
    "    inputs, targets = inputs.cuda(), targets.cuda()\n",
    "print(inputs.shape)\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "plt.imshow(inputs.detach().cpu().numpy()[idx, 0])\n",
    "#plt.imshow(targets.detach().cpu().numpy()[idx, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(targets.detach().cpu().numpy()[1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torchvision.models.segmentation import fcn_resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = fcn_resnet50(num_classes=1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import segmentation as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))\n",
    "print(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = '/scratch/gallowaa/cciw/logs/checkpoint/fcn_resnet50_bs50_wd5e-04_def_1.ckpt'\n",
    "print('==> Resuming from checkpoint..')\n",
    "checkpoint = torch.load(resume)\n",
    "net = checkpoint['net']\n",
    "best_acc = checkpoint['loss']\n",
    "start_epoch = checkpoint['epoch'] + 1\n",
    "torch.set_rng_state(checkpoint['rng_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = segmentation.__dict__['fcn_resnet50'](num_classes=1)\n",
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'%.e' % 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net.eval()\n",
    "net.train()\n",
    "print(net.training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = net(inputs)['out']\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_nhwc = inputs.permute(0, 2, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(8, 3))\n",
    "ax1.imshow(inputs_nhwc.detach().cpu().numpy()[idx])\n",
    "ax2.imshow(pred.detach().cpu().numpy()[idx, 0])\n",
    "ax3.imshow(targets.detach().cpu().numpy()[idx, 0])\n",
    "ax1.set_title('Image')\n",
    "ax2.set_title('Logits')\n",
    "ax3.set_title('Labels')\n",
    "ax1.axis('off')\n",
    "ax2.axis('off')\n",
    "ax3.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(pred.detach().cpu().numpy()[idx, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(torch.argmax(pred, dim=1).detach().cpu().numpy()[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(targets * 255).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn(pred, targets * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    for batch, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        pred = net(inputs)['out']\n",
    "        loss = loss_fn(pred, targets * 255)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'\n",
    "          .format(epoch + 1, epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pixel_acc(targets, targets)\n",
    "pixel_acc(pred, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_acc(pred, label):\n",
    "    #_, preds = torch.max(pred, dim=1)\n",
    "    preds = torch.argmax(pred, dim=1)\n",
    "    valid = (label >= 0).long()\n",
    "    acc_sum = torch.sum(valid * (preds == label).long())\n",
    "    pixel_sum = torch.sum(valid)\n",
    "    acc = acc_sum.float() / (pixel_sum.float() + 1e-10)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationModuleBase(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SegmentationModuleBase, self).__init__()\n",
    "\n",
    "    def pixel_acc(self, pred, label):\n",
    "        _, preds = torch.max(pred, dim=1)\n",
    "        valid = (label >= 0).long()\n",
    "        acc_sum = torch.sum(valid * (preds == label).long())\n",
    "        pixel_sum = torch.sum(valid)\n",
    "        acc = acc_sum.float() / (pixel_sum.float() + 1e-10)\n",
    "        return acc\n",
    "\n",
    "\n",
    "class SegmentationModule(SegmentationModuleBase):\n",
    "    def __init__(self, net_enc, net_dec, crit, deep_sup_scale=None):\n",
    "        super(SegmentationModule, self).__init__()\n",
    "        self.encoder = net_enc\n",
    "        self.decoder = net_dec\n",
    "        self.crit = crit\n",
    "        self.deep_sup_scale = deep_sup_scale\n",
    "\n",
    "    def forward(self, feed_dict, *, segSize=None):\n",
    "        # training\n",
    "        if segSize is None:\n",
    "            if self.deep_sup_scale is not None: # use deep supervision technique\n",
    "                (pred, pred_deepsup) = self.decoder(self.encoder(feed_dict['img_data'], return_feature_maps=True))\n",
    "            else:\n",
    "                pred = self.decoder(self.encoder(feed_dict['img_data'], return_feature_maps=True))\n",
    "\n",
    "            loss = self.crit(pred, feed_dict['seg_label'])\n",
    "            if self.deep_sup_scale is not None:\n",
    "                loss_deepsup = self.crit(pred_deepsup, feed_dict['seg_label'])\n",
    "                loss = loss + loss_deepsup * self.deep_sup_scale\n",
    "\n",
    "            acc = self.pixel_acc(pred, feed_dict['seg_label'])\n",
    "            return loss, acc\n",
    "        # inference\n",
    "        else:\n",
    "            pred = self.decoder(self.encoder(feed_dict['img_data'], return_feature_maps=True), segSize=segSize)\n",
    "            return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
