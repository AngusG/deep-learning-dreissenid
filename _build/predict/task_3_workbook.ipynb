{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "#import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "import transforms as T\n",
    "#from torchvision import transforms\n",
    "\n",
    "#from torchvision.models import segmentation as models\n",
    "\n",
    "#from sklearn.metrics import jaccard_similarity_score as jsc\n",
    "from sklearn.metrics import jaccard_score as jsc\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from task_3_utils import evaluate\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from folder2lmdb import VOCSegmentationLMDB\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('Found GPU ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torchvision.models.segmentation import fcn_resnet50\n",
    "#net = fcn_resnet50(num_classes=1).cuda()\n",
    "#net = models.__dict__['deeplabv3_resnet50'](num_classes=1, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/scratch/gallowaa/cciw/logs/v1.0.1/checkpoint/'\n",
    "#ckpt_file = 'unet_bn_bs32_wd5e-04_unet_lmdb_1234.ckpt'\n",
    "#ckpt_file = 'unet_bs32_wd5e-04_unet_lmdb_12345.ckpt'\n",
    "#ckpt_file = 'unet_bs32_wd1e-03_unet_lmdb_12345.ckpt'\n",
    "ckpt_file = 'unet_bs32_wd1e-03_unet_lmdb_123456.ckpt'\n",
    "\n",
    "\n",
    "#root = '/scratch/gallowaa/cciw/logs/v0.2.4/checkpoint'\n",
    "#ckpt_file = 'fcn_resnet50_bs40_wd5e-04_def_1.ckpt'\n",
    "\n",
    "#root = '/scratch/gallowaa/cciw/logs/Lab/v1-36-img/checkpoint'\n",
    "#ckpt_file = 'unet_bn_bs32_wd5e-04_pytorch_unet_v4_bi_1.ckpt'\n",
    "\n",
    "print('==> Resuming from checkpoint..')\n",
    "checkpoint = torch.load(os.path.join(root, ckpt_file))\n",
    "net = checkpoint['net']\n",
    "best_acc = checkpoint['loss']\n",
    "start_epoch = checkpoint['epoch'] + 1\n",
    "torch.set_rng_state(checkpoint['rng_state'])\n",
    "\n",
    "print('Loaded model trained to epoch ', start_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = models.__dict__['fcn_resnet50'](num_classes=1)\n",
    "#net = net.cuda()\n",
    "\n",
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))\n",
    "print(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet import UNet\n",
    "#bilinear = True if args.bilinear else False\n",
    "net = UNet(n_channels=3, n_classes=1, bilinear=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fcn import FCN16slim\n",
    "net = FCN16slim(n_class=1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,p in net.named_children():\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_file = 'GLNI_1356-3_2017-08-15_image-1_crop.jpg'\n",
    "#test_file = 'GLNI_1352-1_2017-08-16_image-1_crop.jpg'\n",
    "#test_file = 'GLNI_1346-2_2017-08-17_image-1_crop.jpg'\n",
    "#root_path = '/scratch/ssd/gallowaa/cciw/dataset_raw_v0-2-x/Train/2017-08/'\n",
    "root_path = '/scratch/ssd/gallowaa/cciw/dataset_raw/Test/Lab/done/'\n",
    "\n",
    "#img = cv2.imread(os.path.join(root_path, test_file))\n",
    "#img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss() # sigmoid cross entropy\n",
    "\n",
    "MEAN_NAT = (0.2533962, 0.35527486, 0.11992471)\n",
    "STD_NAT  = (0.1717031, 0.11212555, 0.08487311)\n",
    "\n",
    "MEAN_LAB = (0.2613, 0.2528, 0.2255)\n",
    "STD_LAB  = (0.2637, 0.2546, 0.2306)\n",
    "\n",
    "mytforms = []\n",
    "mytforms.append(T.RandomCrop(224))\n",
    "mytforms.append(T.RandomHorizontalFlip(0.5))\n",
    "mytforms.append(T.RandomVerticalFlip(0.5))\n",
    "mytforms.append(T.ToTensor())\n",
    "mytforms.append(T.Normalize(MEAN_NAT, STD_NAT))\n",
    "mytforms = T.Compose(mytforms)\n",
    "\n",
    "test_tform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = '/scratch/ssd/gallowaa/cciw/Lab'\n",
    "'Lab' in f.split('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.VOCSegmentation(\n",
    "    root='/scratch/ssd/gallowaa/cciw/', year='2012', \n",
    "    image_set='train', download=False,\n",
    "    transforms=mytforms)\n",
    "\n",
    "valset = datasets.VOCSegmentation(\n",
    "    root='/scratch/ssd/gallowaa/cciw/', year='2012', \n",
    "    image_set='val', download=False,\n",
    "    transforms=test_tform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valset = VOCSegmentationLMDB(\n",
    "    root=osp.join('/scratch/ssd/gallowaa/cciw/LMDB/val_v101.lmdb'),\n",
    "    download=False, transforms=test_tform)\n",
    "valloader = DataLoader(valset, batch_size=50, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#root=osp.join('/scratch/ssd/gallowaa/cciw/LMDB/train_v101.lmdb'),\n",
    "trainset_noshuffle = VOCSegmentationLMDB(\n",
    "    root=osp.join('/scratch/ssd/gallowaa/cciw/Lab/train_v100.lmdb'),\n",
    "    download=False, transforms=test_tform)\n",
    "trainloader_noshuffle = DataLoader(trainset_noshuffle, batch_size=500, shuffle=False)\n",
    "print(len(trainloader_noshuffle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 30\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=bs, shuffle=False)\n",
    "#valloader = torch.utils.data.DataLoader(\n",
    "#    valset, num_workers=4, collate_fn=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from task_3_utils import evaluate\n",
    "running_mean = 0\n",
    "total_images = 0\n",
    "for idx, data in enumerate(trainloader_noshuffle):\n",
    "    pos_weight = 1 / ((data[1] == 1).sum().float() / (data[1] == 0).sum())\n",
    "    running_mean += pos_weight\n",
    "    total_images += data[1].shape[0]\n",
    "    print('%d of %d, %.3f' % (idx, len(trainloader_noshuffle), pos_weight))\n",
    "print(running_mean / total_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(running_mean / 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(data[0].detach().cpu().numpy()[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.BCEWithLogitsLoss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/export/mlrg/gallowaa/misc/image-20180310_160144.jpg', 'rb') as f:\n",
    "    bin_data = f.read()\n",
    "print(bin_data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label.tobytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inputs.mean(dim=(1, 2, 3)).numpy())\n",
    "#print(inputs.std(dim=(0, 2, 3)).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = inputs.detach().cpu().numpy()\n",
    "tgt = targets.detach().cpu().numpy()\n",
    "img = np.transpose(img, (0, 2, 3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(img[i] - img[i].min()) / img[i].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 8\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow((img[i] - img[i].min()) / img[i].max())\n",
    "ax2.imshow(tgt[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_iou, val_loss = evaluate(net, valloader, loss_fn, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([[0, 0, 0],\n",
    "                   [0, 1, 0]])\n",
    "\n",
    "y_pred = np.array([[0, 0, 0],\n",
    "                   [0, 1, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsc(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_np.round()[:, 0].reshape(pred_np.shape[0], -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_np.reshape(targets_np.shape[0], -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_np[0].squeeze()[0:10, 0:10] = 1\n",
    "plt.imshow(pred_np[0].round().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(targets_np[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(targets_np[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(pred_np.shape[0]):\n",
    "    #j = 0\n",
    "    #print(pred_np.round().reshape(1, -1).shape)\n",
    "    #print(targets_np.reshape(1, -1).shape)\n",
    "    \"\"\"Throws an exception: Classification metrics can't \n",
    "    handle a mix of multilabel-indicator and multiclass-multioutput \n",
    "    targets if argument values are all zero\"\"\"\n",
    "    print(j, np.unique(targets_np[j]))\n",
    "    try:\n",
    "        print(jsc(pred_np[j].reshape(1, -1).round(), targets_np[j].reshape(1, -1)))\n",
    "              \n",
    "    except ValueError:\n",
    "        print('got value error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(pred_np.round()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.unsqueeze(dim=1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fcn import FCN16s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FCN16s()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = model.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.norm(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for n, p in fcn.named_parameters():\n",
    "        if 'weight' in n.split('.'):\n",
    "            print(n, p.norm(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn = FCN16s(n_class=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, p in fcn.named_children():\n",
    "    print(n, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn(x).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in fcn.parameters():\n",
    "    print(k.mean(), k.std(), k.grad.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weight = torch.FloatTensor([2.6222]).to(device)\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight) # sigmoid cross entropy\n",
    "#loss_fn = nn.BCEWithLogitsLoss() # sigmoid cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainloader_noshuffle) * 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_iou = 0\n",
    "running_loss = 0\n",
    "\n",
    "print(len(valloader))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, targets) in enumerate(valloader):\n",
    "        \n",
    "        targets_np = targets.numpy()\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        pred = net(inputs)\n",
    "\n",
    "        # dataloader outputs targets with shape NHW, but we need NCHW\n",
    "        batch_loss = loss_fn(pred, targets.unsqueeze(dim=1).float())\n",
    "        #print(i, batch_loss.item())\n",
    "        running_loss += batch_loss.item()\n",
    "        \n",
    "        # jaccard similarity (IoU) on CPU\n",
    "        pred_np = sig(pred).detach().cpu().numpy()\n",
    "        #print(i, pred_np.shape, targets_np.shape)\n",
    "\n",
    "        # flatten predictions and targets for IoU calculation\n",
    "        t_one_hot = np.zeros((targets_np.shape[0], 2, targets_np.shape[1], targets_np.shape[2]))\n",
    "        t_one_hot[:, 1, :, :][targets_np == 1] = 1\n",
    "        t_one_hot[:, 0, :, :][targets_np == 0] = 1\n",
    "\n",
    "        p_one_hot = np.zeros((pred_np.shape[0], 2, pred_np.shape[2], pred_np.shape[3]))\n",
    "        p_one_hot[:, 1, :, :][pred_np.squeeze().round() == 1] = 1\n",
    "        p_one_hot[:, 0, :, :][pred_np.squeeze().round() == 0] = 1\n",
    "\n",
    "        iou = jsc(p_one_hot.reshape(pred_np.shape[0], -1),\n",
    "                  t_one_hot.reshape(targets_np.shape[0], -1),\n",
    "                  average='samples')\n",
    "        running_iou += iou\n",
    "        print(i, iou, batch_loss.item())\n",
    "        \n",
    "        break\n",
    "        \n",
    "    print(running_loss / len(valloader))\n",
    "    print(running_iou / len(valloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_iou / len(valloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train loss .4489 with train augs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_np[j].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#j = 9\n",
    "jsc(pred_np.round()[:, 0].reshape(30, -1), targets_np.reshape(30, -1), average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_np[9].round().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(pred_np.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one_hot = np.zeros_like(targets_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_one_hot = np.zeros((30, 2, 250, 250))\n",
    "t_one_hot[:, 1, :, :][targets_np == 1] = 1\n",
    "t_one_hot[:, 0, :, :][targets_np == 0] = 1\n",
    "\n",
    "p_one_hot = np.zeros((30, 2, 250, 250))\n",
    "p_one_hot[:, 1, :, :][pred_np.squeeze().round() == 1] = 1\n",
    "p_one_hot[:, 0, :, :][pred_np.squeeze().round() == 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jsc(p_one_hot.reshape(50, -1), t_one_hot.reshape(50, -1), average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nchw = inputs.permute(0, 2, 3, 1).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nchw.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 6\n",
    "\n",
    "N_PLOTS = 4\n",
    "fig, ax = plt.subplots(1, N_PLOTS, figsize=(14, 4))\n",
    "\n",
    "ax[0].imshow((nchw[j] - nchw[j].min()))\n",
    "ax[1].imshow(pred_np[j].squeeze())\n",
    "ax[2].imshow(pred_np[j].round().squeeze())\n",
    "ax[3].imshow(t_one_hot[j, 1])\n",
    "\n",
    "for i in range(N_PLOTS):\n",
    "    ax[i].axis('off')\n",
    "\n",
    "print(jsc(p_one_hot[j].reshape(1, -1), t_one_hot[j].reshape(1, -1), average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsc(p_one_hot.reshape(30, -1), t_one_hot.reshape(30, -1), average='samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nchw[j].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ct = 0\n",
    "mean_iou = 0\n",
    "with torch.no_grad():    \n",
    "    for batch, (inputs, targets) in enumerate(valloader):\n",
    "        inputs = inputs.cuda()\n",
    "        targets_np = targets.detach().cpu().numpy()\n",
    "        pred = sig(net(inputs))\n",
    "        pred_np = pred.detach().cpu().numpy()       \n",
    "        lbl = targets_np.reshape(targets_np.shape[0], -1)\n",
    "        out = pred_np.round()[:, 0].reshape(pred_np.shape[0], -1)\n",
    "        iou = jsc(out, lbl)\n",
    "        mean_iou += iou\n",
    "        #print(batch, iou)\n",
    "mean_iou /= len(valloader)\n",
    "print('%.4f' % mean_iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.time()-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/scratch/ssd/gallowaa/cciw/VOCdevkit/Validation-v101-originals/JPEGImages/'\n",
    "files = glob.glob(root_path + '*.jpg')\n",
    "files.sort()\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inputs_nchw.dtype)\n",
    "print(inputs[0].unsqueeze(dim=0).dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_nchw = inputs_nchw.contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net(inputs_nchw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img[sy:sy + w, sx:sx + w, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SummaryWriter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = 'unet'\n",
    "lr = 1e-1\n",
    "bs = 32\n",
    "epochs = 100\n",
    "wd = 1e-3\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(arch + '/lr%.e/wd%.e/bs%d/ep%d/seed%d/' % (lr, wd, bs, epochs, seed))\n",
    "\n",
    "\n",
    "arch + '_lr%.e_wd%.e_bs%d_ep%d_seed%d' % (lr, wd, bs, epochs, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 1000\n",
    "sy = 50\n",
    "sx = 0\n",
    "\n",
    "i = 0\n",
    "img = cv2.imread(os.path.join(root_path, files[i]))\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "imgc = img[sy:sy + w, sx:sx + w, :]\n",
    "plt.imshow(imgc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgc = imgc / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgc.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mgc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgc = ((imgc - np.array([0.5, 0.5, 0.5])) / np.array([0.5, 0.5, 0.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgc.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#files = glob.glob(root_path + '*.jpg')\n",
    "\n",
    "#imgc = ((imgc - np.array(MEAN_NAT)) / np.array(STD_NAT))\n",
    "imgt = torch.FloatTensor(imgc).to(device)\n",
    "imgt = imgt / imgt.max()\n",
    "imgt = imgt.unsqueeze(0)\n",
    "inputs_nchw = imgt.permute(0, 3, 1, 2).contiguous()\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = sig(net(inputs_nchw))\n",
    "\n",
    "inputs_nhwc = inputs_nchw.permute(0, 2, 3, 1)\n",
    "\n",
    "idx = 0\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))\n",
    "ax1.imshow(inputs_nhwc.detach().cpu().numpy()[idx])\n",
    "ax2.imshow(pred.detach().cpu().numpy()[idx, 0])\n",
    "ax3.imshow(inputs_nhwc.detach().cpu().numpy()[idx], alpha=0.75)\n",
    "ax3.imshow(pred.detach().cpu().numpy()[idx, 0], alpha=0.5)\n",
    "ax1.axis('off')\n",
    "ax2.axis('off')\n",
    "ax3.axis('off')\n",
    "plt.tight_layout()\n",
    "#fig.savefig('img/' + ckpt_file.split('.')[0] + '_' + files[i].split('.')[0] + '_full.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn([1, 1, 16777217, 2])                                                                                                                                                                                                                   \n",
    "input = x.cuda().contiguous(memory_format=torch.channels_last)                                                                                                                                                                                         \n",
    "kernel_size, stride, padding, dilation, ceil_mode = 1, 1, 0, 1, False                                                                                                                                                                                 \n",
    "torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valloader) * 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pred = sig(net(inputs))\n",
    "\n",
    "inputs_nhwc = inputs.permute(0, 2, 3, 1)\n",
    "inputs_nhwc_np = inputs_nhwc.detach().cpu().numpy()    \n",
    "pred_np = pred.detach().cpu().numpy()\n",
    "targets_np = targets.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_binary_iou(outputs, targets, eps=1e-6):\n",
    "    \"\"\"Returns the average binary intersection-over-union score.\n",
    "    Similar to sklearn.metrics.jaccard_similarity_score.\n",
    "    @param outputs are model predictions (post-sigmoid) in Nx1xHxW format.\n",
    "    @param targets are the labels in NxHxW format.\n",
    "    @param eps is a small constant to prevent division by zero.\n",
    "    \"\"\"\n",
    "    outputs = outputs.squeeze(1).round().long()\n",
    "    # zero if output=0 or pred=0\n",
    "    intersection = (outputs & targets).float().sum((1, 2))\n",
    "    union = (outputs | targets).float().sum((1, 2))\n",
    "    iou = intersection / (union + eps)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_binary_iou(pred, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl = targets_np.reshape(bs, -1)\n",
    "out = pred_np.round()[:, 0].reshape(bs, -1)\n",
    "jscv = jsc(out, lbl)\n",
    "print(jscv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydensecrf.densecrf as dcrf\n",
    "import pydensecrf.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.unary_from_softmax?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_crf(inputs_nhwc_np, pred_np, idx):\n",
    "    MAX_ITER = 10\n",
    "    labels = np.stack([pred_np[idx, 0], 1 - pred_np[idx, 0]])\n",
    "    c, h, w = labels.shape[0], labels.shape[1], labels.shape[2]\n",
    "    labels = labels.astype('float') / labels.max()\n",
    "    U = utils.unary_from_softmax(labels)\n",
    "    U = np.ascontiguousarray(U)\n",
    "    d = dcrf.DenseCRF2D(w, h, c)\n",
    "    d.setUnaryEnergy(U)\n",
    "    \"\"\"\n",
    "    @param compat=3, Potts model - it introduces a penalty for nearby similar \n",
    "    pixels that are assigned different labels. \n",
    "    \"\"\"\n",
    "    # This adds the color-independent term, features are the locations only.\n",
    "    d.addPairwiseGaussian(sxy=3, compat=3)\n",
    "    # This adds the color-dependent term, i.e. features are (x,y,r,g,b).\n",
    "    # im is an image-array, e.g. im.dtype == np.uint8\n",
    "\n",
    "    mean = (0.2613, 0.2528, 0.2255), # mean (RGB)\n",
    "    std  = (0.2637, 0.2546, 0.2306)\n",
    "    image = (((inputs_nhwc_np[idx] * std) + mean) * 255).astype('uint8')\n",
    "\n",
    "    d.addPairwiseBilateral(sxy=80, srgb=13, rgbim=image, compat=10)\n",
    "    Q = d.inference(MAX_ITER)\n",
    "    Q = np.array(Q).reshape((c, h, w))\n",
    "    # binarize output\n",
    "    Q[0][Q[0] >= 0.5] = 1\n",
    "    Q[0][Q[0] < 0.5] = 0\n",
    "    \n",
    "    return Q[0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = (0.2613, 0.2528, 0.2255), # mean (RGB)\n",
    "std  = (0.2637, 0.2546, 0.2306)\n",
    "image = (((inputs_nhwc_np[idx] * std) + mean) * 255).astype('uint8')\n",
    "print(image.min())\n",
    "print(image.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_np.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Q[0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize=(12, 2.5)\n",
    "#figsize=(6, 3)\n",
    "#idx = 2 # train mode\n",
    "for idx in range(len(pred_np)):\n",
    "    if idx == 0 or idx == 5:\n",
    "        \n",
    "        pred_crf = run_crf(inputs_nhwc_np, pred_np, idx)\n",
    "        \n",
    "        fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5, figsize=figsize)\n",
    "        ax1.imshow(inputs_nhwc_np[idx])\n",
    "        ax2.imshow(pred_np[idx, 0])\n",
    "        ax3.imshow(pred_np.round()[idx, 0])\n",
    "        ax4.imshow(pred_crf)\n",
    "        ax5.imshow(targets_np[idx])\n",
    "        lbl = targets_np[idx].reshape(1, -1)\n",
    "        out = pred_np.round()[idx, 0].reshape(1, -1)\n",
    "        out_crf = pred_crf.reshape(1, -1)\n",
    "        ax1.set_title('Image'); ax2.set_title('Logits') \n",
    "        ax3.set_title('IoU %.2f' % jsc(out, lbl)); \n",
    "        ax4.set_title('IoU %.2f' % jsc(out_crf, lbl))\n",
    "        ax5.set_title('Label')\n",
    "        pretty_image([ax1, ax2, ax3, ax4, ax5])\n",
    "        plt.savefig(ckpt_file.split('/')[-1].split('.')[0] + '_lab_val_demo' + '_%d.png' % idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs, targets in trainloader:\n",
    "    inputs, targets = inputs.cuda(), targets.cuda()\n",
    "    break\n",
    "x = inputs.permute(0, 2, 3, 1)\n",
    "print(x.shape)\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.mean(dim=(0, 1, 2))\n",
    "#p = net(inputs)['out']\n",
    "#p.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.std(dim=(0, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.mean(dim=(1, 2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = pytorch_unet.UNet(1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    net(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "relu = nn.ReLU()\n",
    "image_mean = x.mean(dim=(1, 2, 3), keepdim=True)\n",
    "variance = x**2 - image_mean**2\n",
    "variance = relu(variance)  # this relu is critical for grad wrt x\n",
    "stddev = torch.sqrt(variance)\n",
    "min_stddev = torch.rsqrt(\n",
    "    torch.prod(torch.FloatTensor([x.size()[1:]]))).cuda()\n",
    "pixel_value_scale = torch.max(stddev, min_stddev)\n",
    "x = x - image_mean\n",
    "#x = x / pixel_value_scale\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "img = x.detach().cpu().numpy()[idx]\n",
    "\n",
    "ax1.imshow(img)\n",
    "#ax2.imshow(targets.detach().cpu().numpy()[idx])\n",
    "#ax2.imshow(variance[idx].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.mean(dim=(1, 2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 10\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_targets = torch.zeros((targets.size(0), targets.size(1), targets.size(2)))\n",
    "print(val_targets.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_targets.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_iou = 0\n",
    "val_loss = 0\n",
    "for inputs, targets in valloader:\n",
    "    inputs, targets = inputs.cuda(), targets.cuda()\n",
    "    val_targets = torch.zeros(\n",
    "        (targets.size(0), targets.size(1), targets.size(2)), \n",
    "        dtype=torch.long).cuda()\n",
    "    val_targets[targets[:, :, :, 0] == 128] = 1\n",
    "    with torch.no_grad():\n",
    "        pred = net(inputs)['out'] # fprop\n",
    "        batch_iou = eval_binary_iou(sig(pred), val_targets)\n",
    "        val_iou += batch_iou.item()\n",
    "        # dataloader outputs targets with shape NHW, but we need NCHW\n",
    "        val_targets = val_targets.unsqueeze(dim=1).float()\n",
    "        batch_loss = loss_fn(pred, val_targets)\n",
    "        val_loss += batch_loss.item()\n",
    "        print(batch_iou)\n",
    "val_loss /= len(valloader)\n",
    "val_iou /= len(valloader)\n",
    "print('Loss: {:.4f}, IoU: {:.4f}'.format(val_loss, val_iou))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_fn(pred, targets.unsqueeze(1).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.unique(targets.detach().cpu().numpy()[1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(pred.detach().cpu().numpy().reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = pred.squeeze(1).round().long()\n",
    "#outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#figsize=(9, 3)\n",
    "#figsize=(6, 3)\n",
    "#idx = 2 # train mode\n",
    "for idx in range(bs):\n",
    "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4)\n",
    "    ax1.imshow(inputs_nhwc.detach().cpu().numpy()[idx])\n",
    "    ax2.imshow(pred.detach().cpu().numpy()[idx, 0])\n",
    "    ax3.imshow(pred.round().detach().cpu().numpy()[idx, 0])\n",
    "    #ax3.imshow(union.detach().cpu().numpy()[idx])\n",
    "    ax4.imshow(targets.detach().cpu().numpy()[idx])\n",
    "    \n",
    "    #lbl = targets[idx].cpu().numpy().reshape(1, -1)\n",
    "    #out = outputs[idx].cpu().numpy().reshape(1, -1)\n",
    "    #jscv = jsc(out, lbl)\n",
    "\n",
    "    #ax1.set_title('Image'); ax2.set_title('Logits') \n",
    "    #ax3.set_title('IoU %.2f' % iou[idx]); \n",
    "    #ax4.set_title('IoU %.2f' % jscv)\n",
    "    pretty_image([ax1, ax2, ax3, ax4])\n",
    "    #plt.savefig(resume.split('/')[-1].split('.')[0] + '_demo_preds_train' + str(net.training) + '_%d.png' % idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputs.round().int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero if output=0 or pred=0\n",
    "outputs = pred.squeeze(1).round().long()\n",
    "eps = 1e-6\n",
    "intersection = (outputs & targets).float().sum((1, 2))\n",
    "print(intersection)\n",
    "union = (outputs | targets).float().sum((1, 2))\n",
    "print(union)\n",
    "iou = intersection / (union + eps)\n",
    "print(iou.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intersection = torch.m(outputs == targets).float().sum((1, 2))\n",
    "#print(intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iou.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 0.20.2\n",
    "from sklearn.metrics import jaccard_similarity_score as jsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsc(np.array([1, 1]), np.array([1, 1]))\n",
    "jsc(np.array([1, 1]), np.array([1, 0]))\n",
    "jsc(np.array([1, 1, 0]), np.array([1, 0, 0]))\n",
    "jsc(np.array([[1, 1, 0]]), np.array([[1, 0, 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "lbl = targets[0].cpu().numpy().reshape(1, -1)\n",
    "out = outputs[0].cpu().numpy().reshape(1, -1)\n",
    "jscv = jsc(out, lbl)\n",
    "print(jscv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_intersection = torch.mul(pred.squeeze(1), targets.squeeze(1)).sum((1, 2))\n",
    "print(soft_intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_union = (pred.squeeze(1) + targets.squeeze(1)).sum((1, 2)) - soft_intersection\n",
    "soft_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(soft_intersection / soft_union).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_np = iou.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs_nhwc = inputs.permute(0, 2, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_image(axes):\n",
    "    for ax in axes:\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_group in optimizer.param_groups:\n",
    "    print(param_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_group['lr'] = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    for batch, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        pred = net(inputs)['out']\n",
    "        \n",
    "        loss = loss_fn(pred, \n",
    "                       torch.LongTensor(\n",
    "                           targets.unsqueeze(1) * 255)\n",
    "                      )\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'\n",
    "          .format(epoch + 1, epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pixel_acc(targets, targets)\n",
    "pixel_acc(pred, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_acc(pred, label):\n",
    "    #_, preds = torch.max(pred, dim=1)\n",
    "    preds = torch.argmax(pred, dim=1)\n",
    "    valid = (label >= 0).long()\n",
    "    acc_sum = torch.sum(valid * (preds == label).long())\n",
    "    pixel_sum = torch.sum(valid)\n",
    "    acc = acc_sum.float() / (pixel_sum.float() + 1e-10)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationModuleBase(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SegmentationModuleBase, self).__init__()\n",
    "\n",
    "    def pixel_acc(self, pred, label):\n",
    "        _, preds = torch.max(pred, dim=1)\n",
    "        valid = (label >= 0).long()\n",
    "        acc_sum = torch.sum(valid * (preds == label).long())\n",
    "        pixel_sum = torch.sum(valid)\n",
    "        acc = acc_sum.float() / (pixel_sum.float() + 1e-10)\n",
    "        return acc\n",
    "\n",
    "\n",
    "class SegmentationModule(SegmentationModuleBase):\n",
    "    def __init__(self, net_enc, net_dec, crit, deep_sup_scale=None):\n",
    "        super(SegmentationModule, self).__init__()\n",
    "        self.encoder = net_enc\n",
    "        self.decoder = net_dec\n",
    "        self.crit = crit\n",
    "        self.deep_sup_scale = deep_sup_scale\n",
    "\n",
    "    def forward(self, feed_dict, *, segSize=None):\n",
    "        # training\n",
    "        if segSize is None:\n",
    "            if self.deep_sup_scale is not None: # use deep supervision technique\n",
    "                (pred, pred_deepsup) = self.decoder(self.encoder(feed_dict['img_data'], return_feature_maps=True))\n",
    "            else:\n",
    "                pred = self.decoder(self.encoder(feed_dict['img_data'], return_feature_maps=True))\n",
    "\n",
    "            loss = self.crit(pred, feed_dict['seg_label'])\n",
    "            if self.deep_sup_scale is not None:\n",
    "                loss_deepsup = self.crit(pred_deepsup, feed_dict['seg_label'])\n",
    "                loss = loss + loss_deepsup * self.deep_sup_scale\n",
    "\n",
    "            acc = self.pixel_acc(pred, feed_dict['seg_label'])\n",
    "            return loss, acc\n",
    "        # inference\n",
    "        else:\n",
    "            pred = self.decoder(self.encoder(feed_dict['img_data'], return_feature_maps=True), segSize=segSize)\n",
    "            return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dumps_pyarrow(obj):\n",
    "    \"\"\"\n",
    "    Serialize an object.\n",
    "\n",
    "    Returns:\n",
    "        Implementation-dependent bytes-like object\n",
    "    \"\"\"\n",
    "    return pa.serialize(obj).to_buffer()\n",
    "\n",
    "\n",
    "def loads_pyarrow(buf):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        buf: the output of `dumps`.\n",
    "    \"\"\"\n",
    "    return pa.deserialize(buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/scratch/ssd/gallowaa/cciw/Lab/val.lmdb'\n",
    "env = lmdb.open(root, subdir=osp.isdir(root), readonly=True, lock=False, readahead=False, meminit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with env.begin(write=False) as txn:\n",
    "    length = loads_pyarrow(txn.get(b'__len__'))\n",
    "    keys = loads_pyarrow(txn.get(b'__keys__'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "with env.begin(write=False) as txn:\n",
    "    byteflow = txn.get(keys[index])\n",
    "unpacked = loads_pyarrow(byteflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unpacked[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buf = io.BytesIO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buf.write(unpacked[1]) # 250*250*3 = 187500 bytes, v 5982, 921 for label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buf.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = PIL.Image.open(buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab.convert?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#buf.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.tobytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "byteImgIO = io.BytesIO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.save(byteImgIO, \"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.save?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "byteImgIO.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "byteImg = byteImgIO.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataBytesIO = io.BytesIO(byteImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIL.Image.open(dataBytesIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "byteImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in fcn.modules():\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'fan_out'\n",
    "conv1 = nn.Conv2d(3, 4, 3, padding=68)\n",
    "torch.nn.init.kaiming_normal_(conv1.weight, mode=mode, nonlinearity='relu')\n",
    "\n",
    "conv2 = nn.Conv2d(4, 4, 3, padding=1)\n",
    "torch.nn.init.kaiming_normal_(conv2.weight, mode=mode, nonlinearity='relu')\n",
    "\n",
    "pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/2\n",
    "\n",
    "fc6 = nn.Conv2d(4, 12, 7)\n",
    "torch.nn.init.kaiming_normal_(fc6.weight, mode=mode, nonlinearity='relu')\n",
    "\n",
    "fc7 = nn.Conv2d(12, 12, 1)\n",
    "torch.nn.init.kaiming_normal_(fc7.weight, mode=mode, nonlinearity='relu')\n",
    "\n",
    "n_class = 1\n",
    "score_fr = nn.Conv2d(12, n_class, 1)\n",
    "score_pool4 = nn.Conv2d(4, n_class, 1)\n",
    "\n",
    "upscore2 = nn.ConvTranspose2d(\n",
    "    n_class, n_class, 4, stride=2, bias=False)\n",
    "upscore16 = nn.ConvTranspose2d(\n",
    "    n_class, n_class, 32, stride=16, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv1\n",
    "h1 = conv1(x)\n",
    "print(h1.shape)\n",
    "h2 = pool1(conv2(h1))\n",
    "print(h2.shape)\n",
    "\n",
    "# conv2\n",
    "h3 = conv2(h2)\n",
    "print(h3.shape)\n",
    "h4 = pool1(conv2(h3))\n",
    "print(h4.shape)\n",
    "\n",
    "# conv3\n",
    "h5 = conv2(h4)\n",
    "print(h5.shape)\n",
    "h6 = pool1(conv2(h5))\n",
    "print(h6.shape)\n",
    "\n",
    "# conv4\n",
    "h7 = conv2(h6)\n",
    "print(h7.shape)\n",
    "pool4 = pool1(conv2(h7))\n",
    "print('pool4', pool4.shape)\n",
    "\n",
    "# conv5\n",
    "h9 = conv2(pool4)\n",
    "print(h9.shape)\n",
    "h10 = pool1(conv2(h9))\n",
    "print(h10.shape)\n",
    "\n",
    "h11 = fc6(h10)\n",
    "print(h11.shape)\n",
    "\n",
    "h12 = fc7(h11)\n",
    "print(h12.shape)\n",
    "\n",
    "h13 = score_fr(h12)\n",
    "print(h13.shape)\n",
    "h = upscore2(h13)\n",
    "print(h.shape)\n",
    "\n",
    "upscore2_act = h  # 1/16\n",
    "\n",
    "h = score_pool4(pool4)\n",
    "h = h[:, :, 5:5 + upscore2_act.size()[2], 5:5 + upscore2_act.size()[3]]\n",
    "score_pool4c = h  # 1/16\n",
    "\n",
    "h = upscore2_act + score_pool4c\n",
    "\n",
    "h = upscore16(h)\n",
    "h = h[:, :, 27:27 + x.size()[2], 27:27 + x.size()[3]].contiguous()\n",
    "print(h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn.Conv2d(3, 64, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(h13.detach().cpu().numpy().reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(h9.detach().cpu().numpy().reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(h.detach().cpu().numpy().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w = torch.empty([4, 3, 3, 3])\n",
    "torch.nn.init.kaiming_normal_(conv1.weight.data, mode='fan_in', nonlinearity='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1.weight.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
