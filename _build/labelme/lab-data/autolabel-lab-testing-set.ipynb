{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatically label lab data\n",
    "\n",
    "This notebook uses a combination of computer vision techniques, namely adaptive thresholding, morpholohy, and a conditional random field (CRF) to automatically segment the mussels on the black board with white lines in the lab.\n",
    "\n",
    "To do:\n",
    "- estimate number of pixels per square to correct for camera distance\n",
    "- Lab_3800-3_2018-08-13, crop too much from top\n",
    "- Lab_3784-2_2018-07-05, junk on top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pydensecrf.densecrf as dcrf\n",
    "import pydensecrf.utils as utils\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../predict')\n",
    "sys.path.append('../')\n",
    "\n",
    "from power_law import *\n",
    "from data_utils import lblsave\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = osp.join(os.environ['DATA_PATH'], 'cciw/Data')\n",
    "SAVE_PATH = osp.join(os.environ['DATA_PATH'], 'cciw/dataset_raw/Test/Lab-tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagetable_path = os.path.join(DATA_PATH, 'Tables', 'ImageTable.csv')\n",
    "image_df = pd.read_csv(imagetable_path, index_col=0)\n",
    "analysis_path = os.path.join(DATA_PATH, 'Tables', 'Analysis.csv')\n",
    "dive_path = os.path.join(DATA_PATH, 'Tables', 'Dives.csv')\n",
    "analysis_df = pd.read_csv(analysis_path, index_col=0, dtype={'Count':float})\n",
    "dive_df = pd.read_csv(dive_path, index_col=0, parse_dates=['Date'])\n",
    "data_df = pd.merge(analysis_df, dive_df, on='Dive Index', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for all image files in testing set...\n",
    "all_images = glob(os.path.join(DATA_PATH,'Videos_and_stills/TestingSet/Lab/*/*/*/Images/Quad*/*.jpg'))\n",
    "len(all_images)\n",
    "\n",
    "all_images.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df[['16mm', '14mm', '12.5mm', '10mm', '8mm', '6.3mm', '4mm', '2mm']].hist(figsize=(15,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@param blockSize Size of a pixel neighborhood \n",
    "       that is used to calculate a threshold value for the pixel.\n",
    "@param C Constant subtracted from the mean or weighted mean \n",
    "       (see the details below). Normally, it is positive but may be zero \n",
    "       or negative as well.\n",
    "@param k_size morphology structuring element size\n",
    "'''\n",
    "blockSize  = 301\n",
    "C_constant = 2\n",
    "k_size     = 11\n",
    "\n",
    "min_area = 40000\n",
    "max_area = 300000\n",
    "\n",
    "corn = 450\n",
    "buf = 100\n",
    "bottom_cut = 150\n",
    "horiz_cut = 200\n",
    "right_cut = 100\n",
    "\n",
    "# HoughLinesP\n",
    "rho = 10\n",
    "theta = np.pi / 45\n",
    "threshold = 500\n",
    "mLL = 500\n",
    "mLG = 20\n",
    "\n",
    "# Show results along the way\n",
    "DO_PLOT = False\n",
    "\n",
    "# Run conditional random field post processing to retrieve missing shell pieces\n",
    "DO_CRF = False # can increase processing time by 20 seconds per image\n",
    "MAX_ITER = 10\n",
    "\n",
    "SAVE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "k_25 = np.ones((25, 25), np.uint8)\n",
    "k_120 = np.ones((120, 120), np.uint8)\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (k_size, k_size))\n",
    "\n",
    "pix_ct = []\n",
    "mussel_ct = []\n",
    "size_dist = []\n",
    "for i in tqdm(range(len(all_images))):\n",
    "#for i in tqdm(range(5)):\n",
    "    im   = cv2.imread(all_images[i])\n",
    "    rgb  = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    th1  = cv2.adaptiveThreshold(\n",
    "        gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, blockSize, C_constant)\n",
    "    erosion = cv2.erode(th1, kernel, iterations=2)\n",
    "    close = cv2.dilate(erosion, kernel, iterations=1)\n",
    "    '''\n",
    "    @param mode cv2.RETR_EXTERNAL retrieves only the extreme outer contours.\n",
    "    @param method cv2.CHAIN_APPROX_SIMPLE compresses horizontal, vertical, \n",
    "           and diagonal segments and leaves only their end points. For example, \n",
    "           an up-right rectangular contour is encoded with 4 points.\n",
    "    '''\n",
    "    cnts = cv2.findContours(close, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "    for c in cnts:\n",
    "        area = cv2.contourArea(c)\n",
    "        if area > min_area: #and area < max_area:\n",
    "            x, y, w, h = cv2.boundingRect(c)\n",
    "            cv2.rectangle(rgb, (x, y), (x + w, y + h), (36, 255, 12), 5)\n",
    "            close[y:y+h, x:x+w] = 0\n",
    "\n",
    "    if DO_PLOT:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 12))\n",
    "\n",
    "    close[:, :horiz_cut] = 0\n",
    "    close[:, close.shape[1] - right_cut:] = 0\n",
    "    close[close.shape[0] - bottom_cut:, :] = 0\n",
    "    close[:bottom_cut, :] = 0\n",
    "    close = cv2.dilate(close, kernel, iterations=1)\n",
    "\n",
    "    # to remove leftover dots\n",
    "    t = cv2.erode(close, k_25, iterations=1)\n",
    "    mask = cv2.dilate(t, k_120, iterations=1)\n",
    "    seg_mask = close & mask\n",
    "    _, cts = np.unique(seg_mask, return_counts=True) \n",
    "\n",
    "    # may find spurious lines if more than 2M pixels\n",
    "    if cts[1] < 2000000:\n",
    "        linesP = cv2.HoughLinesP(seg_mask, rho, theta, threshold=threshold, minLineLength=mLL, maxLineGap=mLG)\n",
    "        if linesP is not None:\n",
    "            for j in range(len(linesP)):\n",
    "                l = linesP[j][0]\n",
    "                if np.abs(l[1] - l[3]) < 50:\n",
    "                    #print(i, 'found horiz line: ', j)\n",
    "                    x_start = np.minimum(l[0], l[2])\n",
    "                    x_end = np.maximum(l[0], l[2])\n",
    "                    seg_mask[l[3] - buf:l[1] + buf, \n",
    "                             np.maximum(x_start - buf * 10, 0):np.minimum(\n",
    "                                 x_end + buf * 10, seg_mask.shape[1])] = 0\n",
    "\n",
    "    # upper left corner\n",
    "    seg_mask[:corn, :corn] = 0\n",
    "    # upper right corner\n",
    "    seg_mask[:corn, seg_mask.shape[1]-corn:] = 0\n",
    "    # bottom left corner\n",
    "    seg_mask[seg_mask.shape[0]-corn:, :corn] = 0\n",
    "    # bottom right corner\n",
    "    seg_mask[seg_mask.shape[0]-corn:, seg_mask.shape[1]-corn:] = 0\n",
    "\n",
    "    # CRF Post-processing\n",
    "    if DO_CRF:\n",
    "        img = np.ascontiguousarray(rgb)\n",
    "        labels = np.stack([seg_mask, 1 - seg_mask])\n",
    "        c, h, w = labels.shape[0], labels.shape[1], labels.shape[2]\n",
    "        labels = labels.astype('float') / labels.max()\n",
    "\n",
    "        U = utils.unary_from_softmax(labels)\n",
    "        U = np.ascontiguousarray(U)\n",
    "        d = dcrf.DenseCRF2D(w, h, c)\n",
    "        d.setUnaryEnergy(U)\n",
    "        \"\"\"\n",
    "        @param compat=3, Potts model - it introduces a penalty for nearby similar \n",
    "        pixels that are assigned different labels. \n",
    "        \"\"\"\n",
    "        # This adds the color-independent term, features are the locations only.\n",
    "        d.addPairwiseGaussian(sxy=3, compat=3)\n",
    "        # This adds the color-dependent term, i.e. features are (x,y,r,g,b).\n",
    "        # im is an image-array, e.g. im.dtype == np.uint8\n",
    "        d.addPairwiseBilateral(sxy=80, srgb=13, rgbim=img, compat=10)\n",
    "        Q = d.inference(MAX_ITER)\n",
    "        Q = np.array(Q).reshape((c, h, w))\n",
    "        # binarize output\n",
    "        Q[0][Q[0] >= 0.5] = 1\n",
    "        Q[0][Q[0] < 0.5] = 0\n",
    "        crf_mask = (Q[0] * 255).astype('uint8')\n",
    "        _, cts = np.unique(crf_mask, return_counts=True)\n",
    "\n",
    "    pix_ct.append(cts[1] / cts.sum())\n",
    "\n",
    "    if DO_PLOT:\n",
    "        axes[0].set_title(str(i))\n",
    "        axes[0].imshow(rgb)\n",
    "        axes[1].imshow(seg_mask)\n",
    "        for k in range(len(axes.flat)):\n",
    "            axes.flat[k].axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    #cv2.imwrite(mask_file, seg_mask)\n",
    "    #cv2.imwrite(jpeg_file, im)\n",
    "    #lbl = np.zeros((np_img.shape[0], np_img.shape[1]))\n",
    "    #lbl[(np_img[:, :, 2] ==  60)] = 1\n",
    "    seg_mask[seg_mask == 255] = 1\n",
    "    \n",
    "    if SAVE:\n",
    "        mask_file = os.path.join(SAVE_PATH, all_images[i].split('/')[-1].split('.')[0] + '_mask.png')\n",
    "        jpeg_file = os.path.join(SAVE_PATH, all_images[i].split('/')[-1])\n",
    "        lblsave(mask_file, seg_mask) # save as indexed color RGB image\n",
    "\n",
    "        if DO_CRF:\n",
    "            crf_mask_file = os.path.join(SAVE_PATH, all_images[i].split('/')[-1].split('.')[0] + '_mask_crf.png')\n",
    "            crf_mask[crf_mask == 255] = 1\n",
    "            lblsave(crf_mask_file, crf_mask) # save as indexed color RGB image\n",
    "            #cv2.imwrite(crf_mask_file, crf_mask)\n",
    "            \n",
    "    vals, cts = count_mussels(rgb, seg_mask)\n",
    "    \n",
    "    mussel_ct.append(vals[-1])\n",
    "    \n",
    "    cts = cts[2:]\n",
    "    cts = cts * np.prod(scale[i]) / (15 * 26)\n",
    "    #freq, bin_edges = np.histogram(cts[cts > 300], bins=bins)\n",
    "    freq, bin_edges = np.histogram(cts, bins=8)\n",
    "    size_dist.append(freq / freq.sum())\n",
    "    \n",
    "size_dist = np.asarray(size_dist)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare biomass and fraction of mussel pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_ct = np.asarray(pix_ct)\n",
    "\n",
    "lab_targets = np.zeros((len(all_images), 3)) # 0 = biomass, 1 = count\n",
    "true_size_dist = np.zeros((len(all_images), 8))\n",
    "\n",
    "names = ['16mm', '14mm', '12.5mm', '10mm', '8mm', '6.3mm', '4mm', '2mm']\n",
    "\n",
    "names.reverse()\n",
    "print(names)\n",
    "sieves = np.array([16, 14, 12.5, 10, 8, 6.3, 4, 2])\n",
    "sieves = sieves[np.argsort(sieves)]\n",
    "\n",
    "for i in range(len(all_images)):\n",
    "#for i in range(5):\n",
    "    root_fname = all_images[i].split('/')[-1].split('.')[0][4:-8]\n",
    "    guid = image_df[image_df['Name'].str.contains(root_fname)]['Analysis Index'].astype('int64')\n",
    "    row = data_df[data_df['Analysis Index'].values == np.unique(guid.values)]\n",
    "    lab_targets[i, 0] = row['Biomass'].values\n",
    "    lab_targets[i, 1] = row['Count'].values\n",
    "    \n",
    "    #size_dist = np.zeros(len(names))\n",
    "    for j in range(len(names)):\n",
    "        true_size_dist[i, j] = row[names[j]].values\n",
    "        #size_dist[j] = row[names[j]].values        \n",
    "        \n",
    "    lab_targets[i, 2] = (lab_targets[i, 0] * true_size_dist[i, :] * (2 / sieves)).sum()\n",
    "\n",
    "x = pix_ct / pix_ct.max()\n",
    "biomass = lab_targets[:, 0]\n",
    "count = lab_targets[:, 1]\n",
    "count_fr_bio_sz = lab_targets[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual camera calibration\n",
    "scale = np.load('../../predict/npy/lab_board_dims_n40.npy')\n",
    "\n",
    "pix_ct_s = pix_ct.copy()\n",
    "for i in range(len(all_images)):\n",
    "    pix_ct_s[i] = pix_ct[i] * (np.prod(scale[i]) / (16 * 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 16\n",
    "def plot_powerlaw_1x1(x_data, y_data, x_label='', y_label=''):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "    power_law_prediction_ax(ax, x_data, y_data, -2, 0, fontsize)\n",
    "    ax.set_ylabel(y_label, fontsize=fontsize)\n",
    "    ax.set_xlabel(x_label, fontsize=fontsize)\n",
    "    ax.tick_params(labelsize=fontsize)\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "fig = plot_powerlaw_1x1(pix_ct_s, biomass, x_label='Predicted Biomass \\n Classic Vision', y_label='Biomass')\n",
    "#fig.savefig('lab_auto_biomass_basic.eps')\n",
    "#fig.savefig('lab_auto_biomass_basic_camera.eps')\n",
    "\n",
    "# Predict count from pixels (basic algorithm)\n",
    "fig = plot_powerlaw_1x1(pix_ct, count, x_label='Predicted Count \\n Classic Vision', y_label='Count')\n",
    "fig.savefig('lab_auto_count_basic.eps')\n",
    "\n",
    "# Predict count from camera adjusted basic algorithm\n",
    "fig = plot_powerlaw_1x1(pix_ct_s, count, x_label='Predicted Count \\n Classic Vision', y_label='Count')\n",
    "fig.savefig('lab_auto_count_basic_camera.eps')\n",
    "\n",
    "# Predict count from watershed + basic algorithm\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "power_law_prediction_ax(ax, pcount, count, 1, 3, fontsize)\n",
    "ax.set_ylabel('Count', fontsize=fontsize)\n",
    "ax.set_xlabel('Predicted Count \\n Classic Vision', fontsize=fontsize)\n",
    "ax.tick_params(labelsize=fontsize)\n",
    "plt.tight_layout()\n",
    "fig.savefig('lab_auto_count_basic_watershed.eps')\n",
    "\n",
    "# Plot count from biomass, or biomass + size distribution\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "#power_law_prediction_ax(ax, biomass, count, 1, 3, fontsize)\n",
    "power_law_prediction_ax(ax, count_fr_bio_sz, count, 0.5, 2.5, fontsize)\n",
    "ax.set_ylabel('Count', fontsize=fontsize)\n",
    "ax.set_xlabel('Biomass + \\n Size Distribution', fontsize=fontsize)\n",
    "#ax.set_xlabel('Biomass', fontsize=fontsize)\n",
    "ax.tick_params(labelsize=fontsize)\n",
    "plt.tight_layout()\n",
    "#fig.savefig('lab_auto_count_basic_watershed.eps')\n",
    "fig.savefig('lab_count_from_biomass_and_distribution.eps')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcount = np.asarray(mussel_ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Mussels Watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_mussels(image, predictions):\n",
    "    \"\"\" Counts mussels in predicted output.\n",
    "    \n",
    "    @param predictions: greyscale predictions as float in [0, 1]\n",
    "    \"\"\"\n",
    "    thresh = (predictions * 255).astype('uint8')\n",
    "\n",
    "    # noise removal\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    opening = cv2.morphologyEx(predictions, cv2.MORPH_OPEN, kernel, iterations = 2)\n",
    "\n",
    "    # sure background area\n",
    "    sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
    "\n",
    "    # Finding sure foreground area\n",
    "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
    "\n",
    "    ret, sure_fg = cv2.threshold(dist_transform, 0.4 * dist_transform.max(), 255, 0)\n",
    "\n",
    "    # Finding unknown region\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "\n",
    "    # Marker labelling\n",
    "    ret, markers = cv2.connectedComponents(sure_fg)\n",
    "\n",
    "    # Add one to all labels so that sure background is not 0, but 1\n",
    "    markers = markers + 1\n",
    "\n",
    "    # Now, mark the region of unknown with zero\n",
    "    markers[unknown == 255] = 0\n",
    "\n",
    "    markers = cv2.watershed(image, markers)\n",
    "    #image[markers == -1] = [255, 0, 0]\n",
    "    \n",
    "    vals, cts = np.unique(markers, return_counts=True)\n",
    "    '''\n",
    "    bonus = 0\n",
    "    div = 7500.\n",
    "    for v in cts[2:][cts[2:] > div]:\n",
    "        bonus += np.floor(v / div)\n",
    "    '''\n",
    "    \n",
    "    return vals, cts #vals[-1] # + bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seg_mask[1500:1570, 200:270] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(16, 10))\n",
    "#plt.imshow(seg_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals, cts = count_mussels(rgb, seg_mask)\n",
    "cts = cts[2:]\n",
    "cts = cts * np.prod(scale[-1]) / (15 * 26)\n",
    "len(cts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cts.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "If *bins* is a sequence, it defines the bin edges, including the\n",
    "left edge of the first bin and the right edge of the last bin;\n",
    "in this case, bins may be unequally spaced.  All but the last\n",
    "(righthand-most) bin is half-open.  In other words, if *bins* is::\n",
    "\n",
    "    [1, 2, 3, 4]\n",
    "\n",
    "then the first bin is ``[1, 2)`` (including 1, but excluding 2) and\n",
    "the second ``[2, 3)``.  The last bin, however, is ``[3, 4]``, which\n",
    "*includes* 4.\n",
    "'''\n",
    "bins = 100 * sieves\n",
    "bins = np.concatenate((bins, np.array([15000.])))\n",
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq, bin_edges = np.histogram(cts[cts > 300], bins=bins)\n",
    "freq / freq.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = plt.hist(cts, bins=bins, align='mid', rwidth=0.8)\n",
    "plt.xlabel('Number of pixels')\n",
    "plt.ylabel('Frequency')\n",
    "print(r[0] / r[0].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = true_size_dist.copy()\n",
    "x = true_size_dist.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = size_dist.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MI = -np.dot(p_xy, np.log2(p_xy / p_x_y))\n",
    "print(MI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MI = -np.dot(p_x_y, np.log2(p_xy / p_xy))\n",
    "print(MI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(x, y.T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joint distribution\n",
    "p_xy = 0\n",
    "for i in range(len(x)):\n",
    "    p_xy += (x[i] * y[i])\n",
    "p_xy #/= len(x)\n",
    "\n",
    "# product of marginals\n",
    "p_x_y = np.dot(np.sum(x, axis=0), np.sum(y, axis=0))\n",
    "\n",
    "MI = -np.dot(p_xy, np.log2(p_xy / p_x_y))\n",
    "print(MI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.dot(x, y.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_x_y = np.dot(np.mean(x, axis=0), np.mean(y, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(sieves, np.mean(np.round(size_dist, 3)[:, :8], axis=0))\n",
    "plt.xlabel('Sieve diameter (mm)', fontsize=fontsize)\n",
    "plt.ylabel('Normalized Frequency', fontsize=fontsize)\n",
    "plt.tick_params(labelsize=fontsize-4)\n",
    "plt.tight_layout()\n",
    "plt.savefig('pred_size_dist_eq_bins.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(sieves, np.mean(np.round(true_size_dist, 3), axis=0))\n",
    "plt.xlabel('Sieve diameter (mm)', fontsize=fontsize)\n",
    "plt.ylabel('Normalized Frequency', fontsize=fontsize)\n",
    "plt.tick_params(labelsize=fontsize-4)\n",
    "plt.tight_layout()\n",
    "plt.savefig('true_size_dist.eps')\n",
    "#plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#size_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mi(size_dist[:, :8], true_size_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-np.dot(np.mean(y, axis=0), np.log2(np.mean(y, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = 10\n",
    "px = np.random.beta(0.6, 0.5, S)\n",
    "px /= px.sum()\n",
    "pz = np.random.beta(0.6, 0.5, S)\n",
    "pz /= pz.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mi(T, Y, num_classes=8):\n",
    "    \"\"\"\n",
    "    Computes the mutual information I(T; Y) between predicted T and true labels Y\n",
    "    as I(T;Y) = H(Y) - H(Y|T) = H_Y - H_cond_YgT\n",
    "    @param T: vector with dimensionality (num_instances,)\n",
    "    @param Y: vector with dimensionality (num_instances,)\n",
    "    @param num_classes: number of classes, default=10\n",
    "    \"\"\"\n",
    "    #Y = Y.detach().cpu().numpy()\n",
    "    #T = T.detach().cpu().numpy()\n",
    "\n",
    "    epsilon = 1e-4 # to prevent divide by zero\n",
    "    num_instances = Y.shape[0]\n",
    "    py    = np.zeros(num_classes) # p(y)\n",
    "    pt    = np.zeros(num_classes) # p(t)\n",
    "    pygt  = np.zeros(num_classes) # p(y|t)\n",
    "    H_YgT = np.zeros(num_classes) # H(Y|T)\n",
    "\n",
    "    # Compute H(Y)\n",
    "    for i in range(num_classes):\n",
    "        py[i] = np.sum(Y == i) / float(num_instances)\n",
    "        pt[i] = np.sum(T == i) / float(num_instances)\n",
    "        \n",
    "    H_Y = -np.dot( py, np.log2(py + epsilon) ) # H(Y)\n",
    "\n",
    "    # Compute H(Y | T)\n",
    "    for t in range(num_classes):\n",
    "        t_idx = T == t \n",
    "        for y in range(num_classes):\n",
    "            y_idx = Y == y\n",
    "            pygt[y] = np.sum(y_idx[t_idx])\n",
    "\n",
    "        # convert counts to probabilities\n",
    "        c = np.sum(pygt)\n",
    "        if c > 0:\n",
    "            pygt /= c\n",
    "            H_YgT[t] = -np.dot( pygt, np.log2(pygt + epsilon) )\n",
    "    \n",
    "    H_cond_YgT = np.dot( pt, H_YgT )\n",
    "\n",
    "    return H_Y - H_cond_YgT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRF Stratch Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Deprecated figure style\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "ax.scatter(pix_ct, y, marker='o', s=40, facecolors='none', edgecolors='b')\n",
    "ax.set_ylabel('Mussel Biomass (g)')\n",
    "#ax.set_xlim(0, 1.05)\n",
    "ax.set_xlabel('Fraction of Pixels Labelled Mussel')\n",
    "\n",
    "x = np.linspace(0, 0.3)\n",
    "ax.plot(x, m*x + c, 'b', linestyle='-')\n",
    "ax.annotate(r'r = %.4f' % r_val, xy=(.06, .805), fontsize=16, xycoords='axes fraction')\n",
    "\n",
    "ax.grid()\n",
    "fname = 'TestingSet_Lab_biomass_v_fract_mussel_pixels_v2'\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(fname + '.png')\n",
    "fig.savefig(fname + '.eps', format='eps')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_mask = seg_mask[:-273, 1250:3250]\n",
    "mask = mask[:-273, 1250:3250]\n",
    "rgb = rgb[:-273, 1250:3250, :]\n",
    "w = 640\n",
    "seg = cv2.resize(seg_mask, (w, w))\n",
    "rgb = cv2.resize(rgb, (w, w))\n",
    "msk = cv2.resize(mask, (w, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = seg_mask.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imask = np.invert(msk).astype('bool')\n",
    "#imask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imask.astype('bool').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rgb[imask] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w = 640\n",
    "#seg = cv2.resize(seg_mask, (w, w))\n",
    "#rgb = cv2.resize(rgb, (w, w))\n",
    "img = np.ascontiguousarray(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.ascontiguousarray(rgb)\n",
    "labels = np.stack([seg, 1 - seg])\n",
    "c = labels.shape[0]\n",
    "h = labels.shape[1]\n",
    "w = labels.shape[2]\n",
    "labels = labels.astype('float') / labels.max()\n",
    "\n",
    "U = utils.unary_from_softmax(labels)\n",
    "U = np.ascontiguousarray(U)\n",
    "d = dcrf.DenseCRF2D(w, h, c)\n",
    "d.setUnaryEnergy(U)\n",
    "MAX_ITER = 10\n",
    "POS_W = 3\n",
    "POS_XY_STD = 10\n",
    "Bi_W = 40\n",
    "Bi_XY_STD = 67\n",
    "Bi_RGB_STD = 30\n",
    "\n",
    "# This adds the color-independent term, features are the locations only.\n",
    "\"\"\"\n",
    "@param compat=3, Potts model - it introduces a penalty for nearby similar \n",
    "pixels that are assigned different labels. \n",
    "\"\"\"\n",
    "d.addPairwiseGaussian(sxy=3, compat=3)\n",
    "# This adds the color-dependent term, i.e. features are (x,y,r,g,b).\n",
    "# im is an image-array, e.g. im.dtype == np.uint8 and im.shape == (640,480,3)\n",
    "d.addPairwiseBilateral(sxy=80, srgb=13, rgbim=img, compat=10)\n",
    "Q = d.inference(MAX_ITER)\n",
    "Q = np.array(Q).reshape((c, h, w))\n",
    "\n",
    "crf_mask = (Q[0] * 255).astype('uint8')\n",
    "crf_mask_file = os.path.join(SAVE_PATH, all_images[i].split('/')[-1].split('.')[0] + '_mask_crf.png')\n",
    "cv2.imwrite(crf_mask_file, fmask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "addPairwiseGaussian\n",
    "- `sxy` = $\\theta_{\\gamma}$, smoothness kernel\n",
    "\n",
    "addPairwiseBilateral\n",
    "- `sxy` = $\\theta_{\\alpha}$, appearance kernel\n",
    "- `srgb` = $\\theta_{\\beta}$, appearance kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font=28\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 8))\n",
    "axes[0].imshow(rgb)\n",
    "axes[0].set_title('RGB input', fontsize=font)\n",
    "axes[1].imshow(seg)\n",
    "axes[1].set_title('Rough mask', fontsize=font)\n",
    "#Q[0][Q[0] >= 0.5] = 1\n",
    "#Q[0][Q[0] < 0.5] = 0\n",
    "axes[2].imshow(Q[0])\n",
    "axes[2].set_title('CRF output', fontsize=font)\n",
    "\n",
    "for i in range(len(axes)):\n",
    "    axes[i].axis('off')\n",
    "\n",
    "#plt.tight_layout()\n",
    "#fig.savefig(all_images[i].split('/')[-1].split('.')[0] + '_CRF_1x3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "#all_images[i].split('/')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fmask = Q[0].astype()\n",
    "#Q[0][Q[0] >= 0.5] = 1\n",
    "#Q[0][Q[0] < 0.5] = 0\n",
    "fmask = (Q[0] * 255).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf_mask_file = os.path.join(SAVE_PATH, all_images[i].split('/')[-1].split('.')[0] + '_mask_crf.png')\n",
    "cv2.imwrite(crf_mask_file, fmask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_mask_bak = seg_mask.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_mask = seg_mask_bak.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 10  \n",
    "theta = np.pi / 45\n",
    "threshold = 500\n",
    "mLL = 500\n",
    "mLG = 20\n",
    "linesP = cv2.HoughLinesP(seg_mask, rho, theta, threshold=threshold, minLineLength=mLL, maxLineGap=mLG)\n",
    "print(len(linesP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(seg_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(linesP)\n",
    "buf = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_width = 10\n",
    "#N = 5\n",
    "if linesP is not None:\n",
    "    for i in range(len(linesP)):\n",
    "        l = linesP[i][0]\n",
    "        pt1 = (l[0], l[1])\n",
    "        pt2 = (l[2], l[3])\n",
    "        if np.abs(l[1] - l[3]) < 50:\n",
    "            print('Found horiz line', pt1, pt2)\n",
    "            cv2.line(rgb, pt1, pt2, (255, 0, 255), line_width, cv2.LINE_AA)\n",
    "            seg_mask[l[3] - buf:l[1] + buf, l[0] - buf * 4:l[2] + buf * 4] = 0\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.imshow(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pix_ct = pix_ct / pix_ct.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "from scipy.stats.distributions import t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images[0].split('/')[-1].split('.')[0][4:-8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_fname = all_images[0].split('/')[-1].split('.')[0][4:-8]\n",
    "guid = image_df[image_df['Name'].str.contains(root_fname)]['Analysis Index'].astype('int64')\n",
    "row = data_df[data_df['Analysis Index'].values == np.unique(guid.values)]\n",
    "lab_targets[i, 0] = row['Biomass'].values\n",
    "lab_targets[i, 1] = row['Count'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lab_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#v, cts = np.unique(mask, return_counts=True)\n",
    "#print(cts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good = close.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_size = 25\n",
    "kernel = np.ones((k_size, k_size), np.uint8)\n",
    "t = cv2.erode(close, kernel, iterations=1)\n",
    "\n",
    "k_size = 120\n",
    "kernel = np.ones((k_size, k_size), np.uint8)\n",
    "mask = cv2.dilate(t, kernel, iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(erosion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 12))\n",
    "axes[0].imshow(close)\n",
    "#clean_mask = close[mask == 1] = 1\n",
    "axes[1].imshow(mask)\n",
    "for i in range(len(axes.flat)):\n",
    "    axes.flat[i].axis('off')\n",
    "plt.show() #pause(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except ImportError:\n",
    "    import pickle\n",
    "\n",
    "from pystruct import learners\n",
    "import pystruct.models as crfs\n",
    "from pystruct.utils import SaveLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cvxopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['X'][:10][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train['Y'][:10][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train = pickle.load()\n",
    "# https://rebeccabilbro.github.io/convert-py2-pickles-to-py3/\n",
    "with open('/scratch/ssd/data/CRF_Tut/data_train.pickle', 'rb') as f:\n",
    "    data_train = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train = pickle.load(open(\"/scratch/ssd/data/CRF_Tut/data_train.pickle\"))\n",
    "C = 0.01\n",
    "\n",
    "n_states = 21\n",
    "print(\"number of samples: %s\" % len(data_train['X']))\n",
    "class_weights = 1. / np.bincount(np.hstack(data_train['Y']))\n",
    "class_weights *= 21. / np.sum(class_weights)\n",
    "print(class_weights)\n",
    "\n",
    "model = crfs.EdgeFeatureGraphCRF(inference_method='qpbo',\n",
    "                                 class_weight=class_weights,\n",
    "                                 symmetric_edge_features=[0, 1],\n",
    "                                 antisymmetric_edge_features=[2])\n",
    "\n",
    "experiment_name = \"edge_features_one_slack_trainval_%f\" % C\n",
    "\n",
    "ssvm = learners.NSlackSSVM(\n",
    "    model, verbose=2, C=C, max_iter=100000, n_jobs=-1,\n",
    "    tol=0.0001, show_loss_every=5,\n",
    "    logger=SaveLogger(experiment_name + \".pickle\", save_every=100),\n",
    "    inactive_threshold=1e-3, inactive_window=10, batch_size=100)\n",
    "\n",
    "ssvm.fit(data_train['X'], data_train['Y'])\n",
    "\n",
    "data_val = pickle.load(open(\"data_val_dict.pickle\"))\n",
    "y_pred = ssvm.predict(data_val['X'])\n",
    "\n",
    "# we throw away void superpixels and flatten everything\n",
    "y_pred, y_true = np.hstack(y_pred), np.hstack(data_val['Y'])\n",
    "y_pred = y_pred[y_true != 255]\n",
    "y_true = y_true[y_true != 255]\n",
    "\n",
    "print(\"Score on validation set: %f\" % np.mean(y_true == y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learners.NSlackSSVM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyqpbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import slic\n",
    "from skimage.segmentation import mark_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = slic(rgb, 1000)\n",
    "#slic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbb = mark_boundaries(rgb, segments, color=(0,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(rgbb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.invert(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb[np.invert(mask), :].shape # = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
