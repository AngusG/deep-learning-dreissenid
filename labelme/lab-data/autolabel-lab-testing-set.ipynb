{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatically label lab data\n",
    "\n",
    "This notebook uses a combination of computer vision techniques, namely adaptive thresholding, morpholohy, and a conditional random field (CRF) to automatically segment the mussels on the black board with white lines in the lab.\n",
    "\n",
    "To do:\n",
    "- estimate number of pixels per square to correct for camera distance\n",
    "- Lab_3800-3_2018-08-13, crop too much from top\n",
    "- Lab_3784-2_2018-07-05, junk on top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pydensecrf.densecrf as dcrf\n",
    "import pydensecrf.utils as utils\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = r'/scratch/gallowaa/cciw/Data'\n",
    "SAVE_PATH = '/scratch/ssd/gallowaa/cciw/dataset_raw/Test/Lab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagetable_path = os.path.join(DATA_PATH, 'Tables', 'ImageTable.csv')\n",
    "image_df = pd.read_csv(imagetable_path, index_col=0)\n",
    "analysis_path = os.path.join(DATA_PATH, 'Tables', 'Analysis.csv')\n",
    "dive_path = os.path.join(DATA_PATH, 'Tables', 'Dives.csv')\n",
    "analysis_df = pd.read_csv(analysis_path, index_col=0, dtype={'Count':float})\n",
    "dive_df = pd.read_csv(dive_path, index_col=0, parse_dates=['Date'])\n",
    "data_df = pd.merge(analysis_df, dive_df, on='Dive Index', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for all image files in testing set...\n",
    "all_images = glob(os.path.join(DATA_PATH,'Videos_and_stills/TestingSet/Lab/*/*/*/Images/Quad*/*.jpg'))\n",
    "len(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "\n",
    "\n",
    "def lblsave(filename, lbl):\n",
    "    import imgviz\n",
    "\n",
    "    if osp.splitext(filename)[1] != '.png':\n",
    "        filename += '.png'\n",
    "    # Assume label ranges [-1, 254] for int32,\n",
    "    # and [0, 255] for uint8 as VOC.\n",
    "    if lbl.min() >= -1 and lbl.max() < 255:\n",
    "        lbl_pil = PIL.Image.fromarray(lbl.astype(np.uint8), mode='P')\n",
    "        colormap = imgviz.label_colormap()\n",
    "        lbl_pil.putpalette(colormap.flatten())\n",
    "        lbl_pil.save(filename)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            '[%s] Cannot save the pixel-wise class label as PNG. '\n",
    "            'Please consider using the .npy format.' % filename\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@param blockSize Size of a pixel neighborhood \n",
    "       that is used to calculate a threshold value for the pixel.\n",
    "@param C Constant subtracted from the mean or weighted mean \n",
    "       (see the details below). Normally, it is positive but may be zero \n",
    "       or negative as well.\n",
    "@param k_size morphology structuring element size\n",
    "'''\n",
    "blockSize  = 301\n",
    "C_constant = 2\n",
    "k_size     = 11\n",
    "\n",
    "min_area = 40000\n",
    "max_area = 300000\n",
    "\n",
    "corn = 450\n",
    "buf = 100\n",
    "bottom_cut = 150\n",
    "horiz_cut = 200\n",
    "right_cut = 100\n",
    "\n",
    "# HoughLinesP\n",
    "rho = 10\n",
    "theta = np.pi / 45\n",
    "threshold = 500\n",
    "mLL = 500\n",
    "mLG = 20\n",
    "\n",
    "# Show results along the way\n",
    "DO_PLOT = False\n",
    "\n",
    "# Run conditional random field post processing to retrieve missing shell pieces\n",
    "DO_CRF = True # can increase processing time by 20 seconds per image\n",
    "MAX_ITER = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "k_25 = np.ones((25, 25), np.uint8)\n",
    "k_120 = np.ones((120, 120), np.uint8)\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (k_size, k_size))\n",
    "\n",
    "pix_ct = []\n",
    "for i in tqdm(range(len(all_images))):\n",
    "    im   = cv2.imread(all_images[i])\n",
    "    rgb  = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    th1  = cv2.adaptiveThreshold(\n",
    "        gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, blockSize, C_constant)\n",
    "    erosion = cv2.erode(th1, kernel, iterations=2)\n",
    "    close = cv2.dilate(erosion, kernel, iterations=1)\n",
    "    '''\n",
    "    @param mode cv2.RETR_EXTERNAL retrieves only the extreme outer contours.\n",
    "    @param method cv2.CHAIN_APPROX_SIMPLE compresses horizontal, vertical, \n",
    "           and diagonal segments and leaves only their end points. For example, \n",
    "           an up-right rectangular contour is encoded with 4 points.\n",
    "    '''\n",
    "    cnts = cv2.findContours(close, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "    for c in cnts:\n",
    "        area = cv2.contourArea(c)\n",
    "        if area > min_area: #and area < max_area:\n",
    "            x, y, w, h = cv2.boundingRect(c)\n",
    "            cv2.rectangle(rgb, (x, y), (x + w, y + h), (36, 255, 12), 5)\n",
    "            close[y:y+h, x:x+w] = 0\n",
    "\n",
    "    if DO_PLOT:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 12))\n",
    "\n",
    "    close[:, :horiz_cut] = 0\n",
    "    close[:, close.shape[1] - right_cut:] = 0\n",
    "    close[close.shape[0] - bottom_cut:, :] = 0\n",
    "    close[:bottom_cut, :] = 0\n",
    "    close = cv2.dilate(close, kernel, iterations=1)\n",
    "\n",
    "    # to remove leftover dots\n",
    "    t = cv2.erode(close, k_25, iterations=1)\n",
    "    mask = cv2.dilate(t, k_120, iterations=1)\n",
    "    seg_mask = close & mask\n",
    "    _, cts = np.unique(seg_mask, return_counts=True) \n",
    "\n",
    "    # may find spurious lines if more than 2M pixels\n",
    "    if cts[1] < 2000000:\n",
    "        linesP = cv2.HoughLinesP(seg_mask, rho, theta, threshold=threshold, minLineLength=mLL, maxLineGap=mLG)\n",
    "        if linesP is not None:\n",
    "            for j in range(len(linesP)):\n",
    "                l = linesP[j][0]\n",
    "                if np.abs(l[1] - l[3]) < 50:\n",
    "                    #print(i, 'found horiz line: ', j)\n",
    "                    x_start = np.minimum(l[0], l[2])\n",
    "                    x_end = np.maximum(l[0], l[2])\n",
    "                    seg_mask[l[3] - buf:l[1] + buf, \n",
    "                             np.maximum(x_start - buf * 10, 0):np.minimum(\n",
    "                                 x_end + buf * 10, seg_mask.shape[1])] = 0\n",
    "\n",
    "    # upper left corner\n",
    "    seg_mask[:corn, :corn] = 0\n",
    "    # upper right corner\n",
    "    seg_mask[:corn, seg_mask.shape[1]-corn:] = 0\n",
    "    # bottom left corner\n",
    "    seg_mask[seg_mask.shape[0]-corn:, :corn] = 0\n",
    "    # bottom right corner\n",
    "    seg_mask[seg_mask.shape[0]-corn:, seg_mask.shape[1]-corn:] = 0\n",
    "\n",
    "    # CRF Post-processing\n",
    "    if DO_CRF:\n",
    "        img = np.ascontiguousarray(rgb)\n",
    "        labels = np.stack([seg_mask, 1 - seg_mask])\n",
    "        c, h, w = labels.shape[0], labels.shape[1], labels.shape[2]\n",
    "        labels = labels.astype('float') / labels.max()\n",
    "\n",
    "        U = utils.unary_from_softmax(labels)\n",
    "        U = np.ascontiguousarray(U)\n",
    "        d = dcrf.DenseCRF2D(w, h, c)\n",
    "        d.setUnaryEnergy(U)\n",
    "        \"\"\"\n",
    "        @param compat=3, Potts model - it introduces a penalty for nearby similar \n",
    "        pixels that are assigned different labels. \n",
    "        \"\"\"\n",
    "        # This adds the color-independent term, features are the locations only.\n",
    "        d.addPairwiseGaussian(sxy=3, compat=3)\n",
    "        # This adds the color-dependent term, i.e. features are (x,y,r,g,b).\n",
    "        # im is an image-array, e.g. im.dtype == np.uint8\n",
    "        d.addPairwiseBilateral(sxy=80, srgb=13, rgbim=img, compat=10)\n",
    "        Q = d.inference(MAX_ITER)\n",
    "        Q = np.array(Q).reshape((c, h, w))\n",
    "        # binarize output\n",
    "        Q[0][Q[0] >= 0.5] = 1\n",
    "        Q[0][Q[0] < 0.5] = 0\n",
    "        crf_mask = (Q[0] * 255).astype('uint8')\n",
    "        _, cts = np.unique(crf_mask, return_counts=True)\n",
    "\n",
    "    pix_ct.append(cts[1] / cts.sum())\n",
    "\n",
    "    if DO_PLOT:\n",
    "        axes[0].set_title(str(i))\n",
    "        axes[0].imshow(rgb)\n",
    "        axes[1].imshow(seg_mask)\n",
    "        for k in range(len(axes.flat)):\n",
    "            axes.flat[k].axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    mask_file = os.path.join(SAVE_PATH, all_images[i].split('/')[-1].split('.')[0] + '_mask.png')\n",
    "    jpeg_file = os.path.join(SAVE_PATH, all_images[i].split('/')[-1])\n",
    "    #cv2.imwrite(mask_file, seg_mask)\n",
    "    #cv2.imwrite(jpeg_file, im)\n",
    "    #lbl = np.zeros((np_img.shape[0], np_img.shape[1]))\n",
    "    #lbl[(np_img[:, :, 2] ==  60)] = 1\n",
    "    seg_mask[seg_mask == 255] = 1\n",
    "    lblsave(mask_file, seg_mask) # save as indexed color RGB image\n",
    "\n",
    "    if DO_CRF:\n",
    "        crf_mask_file = os.path.join(SAVE_PATH, all_images[i].split('/')[-1].split('.')[0] + '_mask_crf.png')\n",
    "        crf_mask[crf_mask == 255] = 1\n",
    "        lblsave(crf_mask_file, crf_mask) # save as indexed color RGB image\n",
    "        #cv2.imwrite(crf_mask_file, crf_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.unique(seg_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare biomass and fraction of mussel pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_ct = np.asarray(pix_ct)\n",
    "lab_targets = np.zeros((len(all_images), 2)) # 0 = biomass, 1 = count\n",
    "\n",
    "for i in range(len(all_images)):\n",
    "    root_fname = all_images[i].split('/')[-1].split('.')[0][4:-8]\n",
    "    guid = image_df[image_df['Name'].str.contains(root_fname)]['Analysis Index'].astype('int64')\n",
    "    row = data_df[data_df['Analysis Index'].values == np.unique(guid.values)]\n",
    "    lab_targets[i, 0] = row['Biomass'].values\n",
    "    lab_targets[i, 1] = row['Count'].values\n",
    "\n",
    "lab_targets[np.isnan(lab_targets)] = 0\n",
    "y = lab_targets[:, 0] / lab_targets[:, 0].max()\n",
    "r_val = np.corrcoef(pix_ct, y)[1, 0]\n",
    "\n",
    "A = np.vstack([pix_ct, np.ones(len(pix_ct))]).T\n",
    "m, c = np.linalg.lstsq(A, y, rcond=None)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "ax.scatter(pix_ct, y, marker='o', s=40, facecolors='none', edgecolors='b')\n",
    "ax.set_ylabel('Mussel Biomass (g)')\n",
    "#ax.set_xlim(0, 1.05)\n",
    "ax.set_xlabel('Fraction of Pixels Labelled Mussel')\n",
    "\n",
    "x = np.linspace(0, 0.3)\n",
    "ax.plot(x, m*x + c, 'b', linestyle='-')\n",
    "ax.annotate(r'r = %.4f' % r_val, xy=(.06, .805), fontsize=16, xycoords='axes fraction')\n",
    "\n",
    "ax.grid()\n",
    "fname = 'TestingSet_Lab_biomass_v_fract_mussel_pixels_v2'\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(fname + '.png')\n",
    "#fig.savefig(fname + '.eps', format='eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRF Stratch Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_mask = seg_mask[:-273, 1250:3250]\n",
    "mask = mask[:-273, 1250:3250]\n",
    "rgb = rgb[:-273, 1250:3250, :]\n",
    "w = 640\n",
    "seg = cv2.resize(seg_mask, (w, w))\n",
    "rgb = cv2.resize(rgb, (w, w))\n",
    "msk = cv2.resize(mask, (w, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = seg_mask.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imask = np.invert(msk).astype('bool')\n",
    "#imask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imask.astype('bool').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rgb[imask] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w = 640\n",
    "#seg = cv2.resize(seg_mask, (w, w))\n",
    "#rgb = cv2.resize(rgb, (w, w))\n",
    "img = np.ascontiguousarray(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.ascontiguousarray(rgb)\n",
    "labels = np.stack([seg, 1 - seg])\n",
    "c = labels.shape[0]\n",
    "h = labels.shape[1]\n",
    "w = labels.shape[2]\n",
    "labels = labels.astype('float') / labels.max()\n",
    "\n",
    "U = utils.unary_from_softmax(labels)\n",
    "U = np.ascontiguousarray(U)\n",
    "d = dcrf.DenseCRF2D(w, h, c)\n",
    "d.setUnaryEnergy(U)\n",
    "MAX_ITER = 10\n",
    "POS_W = 3\n",
    "POS_XY_STD = 10\n",
    "Bi_W = 40\n",
    "Bi_XY_STD = 67\n",
    "Bi_RGB_STD = 30\n",
    "\n",
    "# This adds the color-independent term, features are the locations only.\n",
    "\"\"\"\n",
    "@param compat=3, Potts model - it introduces a penalty for nearby similar \n",
    "pixels that are assigned different labels. \n",
    "\"\"\"\n",
    "d.addPairwiseGaussian(sxy=3, compat=3)\n",
    "# This adds the color-dependent term, i.e. features are (x,y,r,g,b).\n",
    "# im is an image-array, e.g. im.dtype == np.uint8 and im.shape == (640,480,3)\n",
    "d.addPairwiseBilateral(sxy=80, srgb=13, rgbim=img, compat=10)\n",
    "Q = d.inference(MAX_ITER)\n",
    "Q = np.array(Q).reshape((c, h, w))\n",
    "\n",
    "crf_mask = (Q[0] * 255).astype('uint8')\n",
    "crf_mask_file = os.path.join(SAVE_PATH, all_images[i].split('/')[-1].split('.')[0] + '_mask_crf.png')\n",
    "cv2.imwrite(crf_mask_file, fmask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "addPairwiseGaussian\n",
    "- `sxy` = $\\theta_{\\gamma}$, smoothness kernel\n",
    "\n",
    "addPairwiseBilateral\n",
    "- `sxy` = $\\theta_{\\alpha}$, appearance kernel\n",
    "- `srgb` = $\\theta_{\\beta}$, appearance kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font=28\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 8))\n",
    "axes[0].imshow(rgb)\n",
    "axes[0].set_title('RGB input', fontsize=font)\n",
    "axes[1].imshow(seg)\n",
    "axes[1].set_title('Rough mask', fontsize=font)\n",
    "#Q[0][Q[0] >= 0.5] = 1\n",
    "#Q[0][Q[0] < 0.5] = 0\n",
    "axes[2].imshow(Q[0])\n",
    "axes[2].set_title('CRF output', fontsize=font)\n",
    "\n",
    "for i in range(len(axes)):\n",
    "    axes[i].axis('off')\n",
    "\n",
    "#plt.tight_layout()\n",
    "#fig.savefig(all_images[i].split('/')[-1].split('.')[0] + '_CRF_1x3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "#all_images[i].split('/')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fmask = Q[0].astype()\n",
    "#Q[0][Q[0] >= 0.5] = 1\n",
    "#Q[0][Q[0] < 0.5] = 0\n",
    "fmask = (Q[0] * 255).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf_mask_file = os.path.join(SAVE_PATH, all_images[i].split('/')[-1].split('.')[0] + '_mask_crf.png')\n",
    "cv2.imwrite(crf_mask_file, fmask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_mask_bak = seg_mask.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_mask = seg_mask_bak.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 10  \n",
    "theta = np.pi / 45\n",
    "threshold = 500\n",
    "mLL = 500\n",
    "mLG = 20\n",
    "linesP = cv2.HoughLinesP(seg_mask, rho, theta, threshold=threshold, minLineLength=mLL, maxLineGap=mLG)\n",
    "print(len(linesP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(seg_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(linesP)\n",
    "buf = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_width = 10\n",
    "#N = 5\n",
    "if linesP is not None:\n",
    "    for i in range(len(linesP)):\n",
    "        l = linesP[i][0]\n",
    "        pt1 = (l[0], l[1])\n",
    "        pt2 = (l[2], l[3])\n",
    "        if np.abs(l[1] - l[3]) < 50:\n",
    "            print('Found horiz line', pt1, pt2)\n",
    "            cv2.line(rgb, pt1, pt2, (255, 0, 255), line_width, cv2.LINE_AA)\n",
    "            seg_mask[l[3] - buf:l[1] + buf, l[0] - buf * 4:l[2] + buf * 4] = 0\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.imshow(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pix_ct = pix_ct / pix_ct.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "from scipy.stats.distributions import t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images[0].split('/')[-1].split('.')[0][4:-8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_fname = all_images[0].split('/')[-1].split('.')[0][4:-8]\n",
    "guid = image_df[image_df['Name'].str.contains(root_fname)]['Analysis Index'].astype('int64')\n",
    "row = data_df[data_df['Analysis Index'].values == np.unique(guid.values)]\n",
    "lab_targets[i, 0] = row['Biomass'].values\n",
    "lab_targets[i, 1] = row['Count'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lab_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#v, cts = np.unique(mask, return_counts=True)\n",
    "#print(cts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good = close.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_size = 25\n",
    "kernel = np.ones((k_size, k_size), np.uint8)\n",
    "t = cv2.erode(close, kernel, iterations=1)\n",
    "\n",
    "k_size = 120\n",
    "kernel = np.ones((k_size, k_size), np.uint8)\n",
    "mask = cv2.dilate(t, kernel, iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(erosion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 12))\n",
    "axes[0].imshow(close)\n",
    "#clean_mask = close[mask == 1] = 1\n",
    "axes[1].imshow(mask)\n",
    "for i in range(len(axes.flat)):\n",
    "    axes.flat[i].axis('off')\n",
    "plt.show() #pause(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except ImportError:\n",
    "    import pickle\n",
    "\n",
    "from pystruct import learners\n",
    "import pystruct.models as crfs\n",
    "from pystruct.utils import SaveLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cvxopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['X'][:10][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train['Y'][:10][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train = pickle.load()\n",
    "# https://rebeccabilbro.github.io/convert-py2-pickles-to-py3/\n",
    "with open('/scratch/ssd/data/CRF_Tut/data_train.pickle', 'rb') as f:\n",
    "    data_train = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train = pickle.load(open(\"/scratch/ssd/data/CRF_Tut/data_train.pickle\"))\n",
    "C = 0.01\n",
    "\n",
    "n_states = 21\n",
    "print(\"number of samples: %s\" % len(data_train['X']))\n",
    "class_weights = 1. / np.bincount(np.hstack(data_train['Y']))\n",
    "class_weights *= 21. / np.sum(class_weights)\n",
    "print(class_weights)\n",
    "\n",
    "model = crfs.EdgeFeatureGraphCRF(inference_method='qpbo',\n",
    "                                 class_weight=class_weights,\n",
    "                                 symmetric_edge_features=[0, 1],\n",
    "                                 antisymmetric_edge_features=[2])\n",
    "\n",
    "experiment_name = \"edge_features_one_slack_trainval_%f\" % C\n",
    "\n",
    "ssvm = learners.NSlackSSVM(\n",
    "    model, verbose=2, C=C, max_iter=100000, n_jobs=-1,\n",
    "    tol=0.0001, show_loss_every=5,\n",
    "    logger=SaveLogger(experiment_name + \".pickle\", save_every=100),\n",
    "    inactive_threshold=1e-3, inactive_window=10, batch_size=100)\n",
    "\n",
    "ssvm.fit(data_train['X'], data_train['Y'])\n",
    "\n",
    "data_val = pickle.load(open(\"data_val_dict.pickle\"))\n",
    "y_pred = ssvm.predict(data_val['X'])\n",
    "\n",
    "# we throw away void superpixels and flatten everything\n",
    "y_pred, y_true = np.hstack(y_pred), np.hstack(data_val['Y'])\n",
    "y_pred = y_pred[y_true != 255]\n",
    "y_true = y_true[y_true != 255]\n",
    "\n",
    "print(\"Score on validation set: %f\" % np.mean(y_true == y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learners.NSlackSSVM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyqpbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import slic\n",
    "from skimage.segmentation import mark_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = slic(rgb, 1000)\n",
    "#slic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbb = mark_boundaries(rgb, segments, color=(0,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(rgbb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.invert(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb[np.invert(mask), :].shape # = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
