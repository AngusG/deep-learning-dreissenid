{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0UXd9CuzgNx2"
   },
   "source": [
    "# Evaluate a Pre-Trained Segmentation Model in Colab\n",
    "\n",
    "Demonstrates image pre-processing, prediction and validation statistics. But first, some preliminaries...\n",
    "\n",
    "__Note:__ To maintain a high priority Colab user status such that sufficient GPU resources are available in the future, ensure to free the runtime when finished running this notebook. This can be done using 'Runtime > Manage Sessions' and click 'Terminate'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if notebook is running in Colab or local workstation\n",
    "import sys\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "    !pip install gputil\n",
    "    !pip install psutil\n",
    "    !pip install humanize\n",
    "\n",
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "GPUs = GPU.getGPUs()\n",
    "\n",
    "try:\n",
    "    # XXX: only one GPU on Colab and isn’t guaranteed\n",
    "    gpu = GPUs[0]\n",
    "    def printm():\n",
    "        process = psutil.Process(os.getpid())\n",
    "        print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    "        print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "    printm() \n",
    "\n",
    "    # Check if GPU capacity is sufficient to proceed\n",
    "    if gpu.memoryFree < 10000:\n",
    "        print(\"\\nInsufficient memory! Some cells may fail. Please try restarting the runtime using 'Runtime → Restart Runtime...' from the menu bar. If that doesn't work, terminate this session and try again later.\")\n",
    "    else:\n",
    "        print('\\nGPU memory is sufficient to proceeed.')\n",
    "except:\n",
    "    print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "    print('and then re-execute this cell.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "4pzGY41DgyyQ",
    "outputId": "6bebf55b-f9f5-4a59-abdd-4c101878f4d1"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    DATA_PATH = r'/content/drive/My Drive/Data'\n",
    "    \n",
    "    # cd into git repo so python can find utils\n",
    "    %cd '/content/drive/My Drive/cciw-zebra-mussel/predict'\n",
    "\n",
    "    sys.path.append('/content/drive/My Drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bneyBxcYgNx7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import csv\n",
    "import glob\n",
    "\n",
    "# for manually reading high resolution images\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# for comparing predictions to lab analysis data frames\n",
    "import pandas as pd\n",
    "\n",
    "# for plotting\n",
    "import matplotlib\n",
    "# enable LaTeX style fonts\n",
    "matplotlib.rc('text', usetex=True)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "\n",
    "# pytorch core library\n",
    "import torch\n",
    "# pytorch neural network functions\n",
    "from torch import nn\n",
    "\n",
    "from sklearn.metrics import jaccard_score as jsc\n",
    "\n",
    "# various helper functions, metrics that can be evaluated on the GPU\n",
    "from task_3_utils import eval_binary_iou, pretty_image, img_to_nchw_tensor, mask_and_preds_to_1hot\n",
    "\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path.\n",
    "\n",
    "from utils.dataset_2_utils import colour_fmt_crop_and_resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Confim that this cell prints \"Found GPU, cuda\". If not, select \"GPU\" as \n",
    "\"Hardware Accelerator\" under the \"Runtime\" tab of the main menu.\n",
    "\"\"\"\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('Found GPU,', device)\n",
    "    \n",
    "sig = nn.Sigmoid()  # initializes a sigmoid function    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n4P0mldogNyQ"
   },
   "source": [
    "## 1. Load the dataset\n",
    "\n",
    "The architecture is fully-convolutional network (FCN) 8s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "rouYvCy3gNzj",
    "outputId": "0cd6d473-73c3-4f2e-97ca-df03fbb55f7a"
   },
   "outputs": [],
   "source": [
    "root_path = '/scratch/ssd/gallowaa/cciw/VOCdevkit/Validation-v101-originals/'\n",
    "jpeg_files = glob.glob(osp.join(root_path, 'JPEGImages/') + '*.jpg')\n",
    "png_files = glob.glob(osp.join(root_path, 'SegmentationClass/') + '*_crop.png')\n",
    "\n",
    "jpeg_files.sort()\n",
    "png_files.sort()\n",
    "\n",
    "# Both should equal 55 for v1.0.1 in-situ dataset\n",
    "print(len(jpeg_files)) \n",
    "print(len(png_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 16\n",
    "\n",
    "left = 0.02  # the left side of the subplots of the figure\n",
    "right = 0.98   # the right side of the subplots of the figure\n",
    "bottom = 0.05  # the bottom of the subplots of the figure\n",
    "top = 0.95     # the top of the subplots of the figure\n",
    "wspace = 0.15  # the amount of width reserved for space between subplots,\n",
    "# expressed as a fraction of the average axis width\n",
    "hspace = 0.1  # the amount of height reserved for space between subplots,\n",
    "# expressed as a fraction of the average axis height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load a pre-trained model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['DATA_PATH'] = '/scratch/gallowaa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = osp.join(os.environ['DATA_PATH'], 'cciw/logs/cmp-dataset/train_v120/')\n",
    "print(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 (resnet50) + 12 (slim) + 3 (unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#files = glob.glob(root + '*/*/*/*/*/*/checkpoint/*epoch79.ckpt')\n",
    "#files = glob.glob(root + 'deeplabv3_resnet50/*/*/*/*/*/checkpoint/*epoch79.ckpt')\n",
    "files = glob.glob(root + 'unet/*/*/*/*/*/checkpoint/*epoch79.ckpt')\n",
    "\n",
    "print(len(files))\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Set to True to save the model predictions in PNG format, \n",
    "otherwise proceed to predict biomass without saving images\"\"\"\n",
    "PLOT = False\n",
    "SAVE_PREDICTIONS = False\n",
    "IOU_C2 = True\n",
    "\n",
    "# src is the training dataset, tgt is the testing dataset\n",
    "src = 'train_v120'\n",
    "tgt = 'val_v101'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "n89QOGLxgNyS",
    "outputId": "904c901b-f3e2-4a84-afd8-27eaad8aadf7"
   },
   "outputs": [],
   "source": [
    "# for f in range(len(files)):\n",
    "for f in range(3):\n",
    "    print('==> Resuming from checkpoint..')\n",
    "\n",
    "    checkpoint = torch.load(osp.join(files[f]))\n",
    "    train_loss = checkpoint['trn_loss']\n",
    "    val_loss = checkpoint['val_loss']\n",
    "\n",
    "    net = checkpoint['net']\n",
    "    last_epoch = checkpoint['epoch']\n",
    "    torch.set_rng_state(checkpoint['rng_state'])\n",
    "\n",
    "    net.eval()\n",
    "\n",
    "    # later appended to figure filenames\n",
    "    model_stem = files[f].split('/')[-1].split('.')[0]\n",
    "    print('Loaded model %s trained to epoch ' % model_stem, last_epoch)\n",
    "    print(\n",
    "        'Cross-entropy loss {:.4f} for train set, {:.4f} for validation set'.format(train_loss, val_loss))\n",
    "\n",
    "    if SAVE_PREDICTIONS:\n",
    "        prediction_path = ''\n",
    "        for t in files[f].split('/')[:-1]:\n",
    "            prediction_path += t + '/'\n",
    "        prediction_path = osp.join(prediction_path, 'predictions')\n",
    "        if not osp.exists(prediction_path):\n",
    "            os.mkdir(prediction_path)\n",
    "        else:\n",
    "            print('Folder', prediction_path, 'already exists')\n",
    "\n",
    "        with open(osp.join(prediction_path, 'val_preds.csv'), 'w') as logfile:\n",
    "            logwriter = csv.writer(logfile, delimiter=',')\n",
    "            logwriter.writerow(['image index', 'miou'])\n",
    "\n",
    "    iou_list = []\n",
    "\n",
    "    #for i in range(3):\n",
    "    for i in range(len(jpeg_files)):\n",
    "\n",
    "        image_stem = jpeg_files[i].split('/')[-1].split('.')[0]\n",
    "        bgr_lab = cv2.imread(osp.join(root_path, png_files[i]))\n",
    "        bgr_img = cv2.imread(osp.join(root_path, jpeg_files[i]))\n",
    "\n",
    "        imgc, mask = colour_fmt_crop_and_resize(\n",
    "            bgr_img, bgr_lab, 0, scale_percent=100)\n",
    "\n",
    "        nchw_tensor = img_to_nchw_tensor(imgc, device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = sig(net(nchw_tensor))\n",
    "            #pred = sig(net(nchw_tensor)['out']) # torchvision models\n",
    "\n",
    "        pred_np = pred.detach().cpu().numpy().squeeze()\n",
    "\n",
    "        if IOU_C2:\n",
    "\n",
    "            p_one_hot, t_one_hot = mask_and_preds_to_1hot(pred_np, mask)\n",
    "\n",
    "            iou = jsc(p_one_hot.reshape(1, -1),\n",
    "                      t_one_hot.reshape(1, -1), average='samples')\n",
    "        else:\n",
    "            targets = torch.LongTensor(mask).to(device)\n",
    "            iou = eval_binary_iou(pred, targets).item()\n",
    "\n",
    "        print('Image %d of %d, IoU %.4f' % (i, len(png_files), iou))\n",
    "        iou_list.append(iou)\n",
    "\n",
    "        if SAVE_PREDICTIONS:\n",
    "            with open(osp.join(prediction_path, 'val_preds.csv'), 'a') as logfile:\n",
    "                logwriter = csv.writer(logfile, delimiter=',')\n",
    "                logwriter.writerow([i, np.round(iou, 4)])\n",
    "    \n",
    "        if PLOT:\n",
    "            plt.close('all')\n",
    "            image = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2RGB)\n",
    "            fig, axes = plt.subplots(1, 3, figsize=(10, 4))\n",
    "            axes = axes.flatten()\n",
    "            axes[0].imshow(image)\n",
    "            axes[0].set_title('Input', fontsize=fontsize)\n",
    "            axes[1].imshow(image, alpha=0.75)\n",
    "            axes[1].imshow(pred_np, alpha=0.5)\n",
    "            axes[1].set_title('Input \\& Preds, IoU = %.4f' %\n",
    "                              iou, fontsize=fontsize)\n",
    "            axes[2].imshow(mask)\n",
    "            axes[2].set_title('Ground Truth', fontsize=fontsize)\n",
    "            plt.subplots_adjust(left=left, bottom=bottom,\n",
    "                                right=right, top=top, wspace=wspace, hspace=hspace)\n",
    "            pretty_image(axes)\n",
    "\n",
    "            if SAVE_PREDICTIONS:\n",
    "                filename = src + '-' + tgt + '__' + image_stem + '__' + model_stem\n",
    "                out_file = osp.join(prediction_path, filename)\n",
    "                fig.savefig(out_file + '.png', format='png')\n",
    "                #fig.savefig(out_file + '.eps', format='eps')\n",
    "\n",
    "    if SAVE_PREDICTIONS:\n",
    "        with open(osp.join(prediction_path, 'val_preds.csv'), 'a') as logfile:\n",
    "            logwriter = csv.writer(logfile, delimiter=',')\n",
    "            logwriter.writerow(\n",
    "                ['mean', np.round(np.asarray(iou_list).mean(), 4)])\n",
    "    else:\n",
    "        print('Seed %d %.4f' % (f, np.asarray(iou_list).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "task_3_evaluate_checkpoint_in_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
