{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0UXd9CuzgNx2"
   },
   "source": [
    "# Evaluate Pre-Trained DeepLabV3 Model Predictions\n",
    "\n",
    "- Outputs CSV file and image predictions (in blue shading) for three DeepLabV3 model ensemble.\n",
    "\n",
    "__Note:__ To maintain a high priority Colab user status such that sufficient GPU resources are available in the future, ensure to free the runtime when finished running this notebook. This can be done using 'Runtime > Manage Sessions' and click 'Terminate'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !ln - sf / opt/bin/nvidia-smi / usr/bin/nvidia-smi\n",
    "    !pip install gputil\n",
    "    !pip install psutil\n",
    "    !pip install humanize\n",
    "    \n",
    "    # Check if notebook is running in Colab or local workstation\n",
    "    import GPUtil as GPU\n",
    "    import humanize\n",
    "    import psutil\n",
    "\n",
    "    GPUs = GPU.getGPUs()\n",
    "\n",
    "    try:\n",
    "        # XXX: only one GPU on Colab and isn’t guaranteed\n",
    "        gpu = GPUs[0]\n",
    "\n",
    "        def printm():\n",
    "            process = psutil.Process(os.getpid())\n",
    "            print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available),\n",
    "                  \" | Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n",
    "            print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(\n",
    "                gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "        printm()\n",
    "\n",
    "        # Check if GPU capacity is sufficient to proceed\n",
    "        if gpu.memoryFree < 10000:\n",
    "            print(\"\\nInsufficient memory! Some cells may fail. Please try restarting the runtime using 'Runtime → Restart Runtime...' from the menu bar. If that doesn't work, terminate this session and try again later.\")\n",
    "        else:\n",
    "            print('\\nGPU memory is sufficient to proceeed.')\n",
    "    except:\n",
    "        print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "        print('and then re-execute this cell.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "4pzGY41DgyyQ",
    "outputId": "6bebf55b-f9f5-4a59-abdd-4c101878f4d1"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    DATA_PATH = r'/content/drive/My Drive/Data'\n",
    "\n",
    "    # cd into git repo so python can find utils\n",
    "    %cd '/content/drive/My Drive/cciw-zebra-mussel/predict'\n",
    "\n",
    "    sys.path.append('/content/drive/My Drive')\n",
    "\n",
    "    # clone repo, install packages not installed by default\n",
    "    !pip install pydensecrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bneyBxcYgNx7"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "\n",
    "# for manually reading high resolution images\n",
    "import cv2\n",
    "\n",
    "# deep learning libs\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# convert opencv image to torch tensor\n",
    "from task_3_utils import img_to_nchw_tensor\n",
    "\n",
    "# progress bar\n",
    "from tqdm import tqdm  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Confim that this cell prints \"Found GPU, cuda\". If not, select \"GPU\" as \n",
    "\"Hardware Accelerator\" under the \"Runtime\" tab of the main menu.\n",
    "\"\"\"\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('Found GPU,', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Meta-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1  # 2, 3\n",
    "\n",
    "\"\"\"Set to True to save the model predictions in PNG format, \n",
    "otherwise proceed to predict biomass without saving images\"\"\"\n",
    "SAVE_PREDICTIONS = True\n",
    "\n",
    "# option 1, validation\n",
    "root_path = '/scratch/ssd/gallowaa/cciw/VOCdevkit/Validation-v102-originals/'  # N=55\n",
    "split = 'val' \n",
    "version = 'v102'\n",
    "scale_percent = 100 # these quadrats already resized from 3000 to 2250 px square\n",
    "\n",
    "# option 2, train\n",
    "#root_path = '/scratch/ssd/gallowaa/cciw/VOCdevkit/Train-v120-originals/'  # N=152\n",
    "#split = 'train'\n",
    "#version = 'v120'\n",
    "#scale_percent = 100 # these quadrats already resized from 3000 to 2250 px square\n",
    "\n",
    "# option 3, test\n",
    "#root_path = '/scratch/ssd/gallowaa/cciw/dataset_raw/unused-train-cropped/'  # N=189\n",
    "#split = 'test'\n",
    "#version = 'v110'\n",
    "#scale_percent = 75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n4P0mldogNyQ"
   },
   "source": [
    "# 2. Load a pre-trained model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['DATA_PATH'] = '/scratch/gallowaa/'\n",
    "\n",
    "if IN_COLAB:\n",
    "    root = osp.join(\n",
    "        DATA_PATH, 'Checkpoints/deeplabv3_resnet50_lr1e-01_wd5e-04_bs40_ep80_seed1')\n",
    "\n",
    "else:\n",
    "    root = osp.join(\n",
    "        os.environ['DATA_PATH'], 'cciw/logs/cmp-dataset/train_v120/deeplabv3_resnet50/lr1e-01/wd5e-04/bs40/ep80/seed%d/checkpoint' % SEED)\n",
    "\n",
    "ckpt_file = 'deeplabv3_resnet50_lr1e-01_wd5e-04_bs40_ep80_seed%d_epoch40.ckpt' % SEED\n",
    "\n",
    "model_to_load = osp.join(root, ckpt_file)\n",
    "\n",
    "print('Loading', model_to_load)\n",
    "\n",
    "checkpoint = torch.load(model_to_load)\n",
    "\n",
    "train_loss = checkpoint['trn_loss']\n",
    "val_loss = checkpoint['val_loss']\n",
    "print('==> Resuming from checkpoint..')\n",
    "net = checkpoint['net']\n",
    "last_epoch = checkpoint['epoch']\n",
    "torch.set_rng_state(checkpoint['rng_state'])\n",
    "\n",
    "# later appended to figure filenames\n",
    "model_stem = ckpt_file.split('.')[0]\n",
    "\n",
    "print('Loaded model %s trained to epoch ' % model_stem, last_epoch)\n",
    "print(\n",
    "    'Cross-entropy loss {:.4f} for train set, {:.4f} for validation set'.format(train_loss, val_loss))\n",
    "\n",
    "sig = nn.Sigmoid()  # initializes a sigmoid function\n",
    "\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "rouYvCy3gNzj",
    "outputId": "0cd6d473-73c3-4f2e-97ca-df03fbb55f7a"
   },
   "outputs": [],
   "source": [
    "# for VOCdevkit root path\n",
    "jpeg_files = glob.glob(osp.join(root_path, 'JPEGImages/') + '*.jpg')\n",
    "png_files = glob.glob(osp.join(root_path, 'SegmentationClass/') + '*_crop.png')\n",
    "png_files.sort()\n",
    "print('Found %d PNG masks' % len(png_files))\n",
    "\n",
    "# otherwise\n",
    "if len(jpeg_files) == 0:\n",
    "    jpeg_files = glob.glob(root_path + '*.jpg')\n",
    "jpeg_files.sort()\n",
    "print('Found %d JPEG images' % len(jpeg_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_PREDICTIONS:\n",
    "    prediction_path = ''\n",
    "    for t in root.split('/')[:-1]:\n",
    "        prediction_path += t + '/'\n",
    "\n",
    "    prediction_path = osp.join(prediction_path, 'predictions-lom-%s-%s' % (split, version))\n",
    "\n",
    "    if not osp.exists(prediction_path):\n",
    "        os.mkdir(prediction_path)\n",
    "\n",
    "    # src is the training dataset, tgt is the testing dataset\n",
    "    src = 'train_v120'\n",
    "    tgt = split + '_' + version\n",
    "    print(prediction_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Do prediction and save as soft-blue images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated July 17, 2020 for LOM journal. Blend soft predictions with orig image.\n",
    "\n",
    "for i in tqdm(range(len(jpeg_files))):\n",
    "\n",
    "    image_stem = jpeg_files[i].split('/')[-1].split('.')[0]\n",
    "\n",
    "    bgr_img = cv2.imread(osp.join(root_path, jpeg_files[i]))\n",
    "    imgc = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    width = int(imgc.shape[1] * scale_percent / 100)\n",
    "    height = int(imgc.shape[0] * scale_percent / 100)\n",
    "    imgc = cv2.resize(imgc, (width, height)) # resize image\n",
    "\n",
    "    nchw_tensor = img_to_nchw_tensor(imgc, device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = sig(net(nchw_tensor)['out']) # remove 'out' for vanilla FCN\n",
    "    pred_np = pred.detach().cpu().numpy().squeeze()\n",
    "\n",
    "    p = (pred_np * 255).astype('uint8')\n",
    "    src2 = np.zeros((p.shape[0], p.shape[1], 3), np.uint8)\n",
    "    src2[:, :, 2] = p\n",
    "    dst = cv2.addWeighted(imgc, 0.75, src2, 0.5, 0.5)\n",
    "\n",
    "    if SAVE_PREDICTIONS:\n",
    "        filename = src + '-' + tgt + '__' + image_stem + '__' + model_stem\n",
    "        out_file = osp.join(prediction_path, filename)\n",
    "        cv2.imwrite(out_file + '_scale%d_preds.jpg' % scale_percent, cv2.cvtColor(dst, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Do prediction and save pixel counts as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell added June 5, 2020 for saving predictions.\n",
    "csvfile = 'predictions_%s-%s_%s' % (split, version, model_stem) \n",
    "csvfile += '.csv'\n",
    "print('Creating', csvfile)\n",
    "\n",
    "with open(csvfile, 'w') as f:\n",
    "    csvwriter = csv.writer(f, delimiter=',')\n",
    "    csvwriter.writerow(['image', 'mussel_pixels', 'total_pixels'])\n",
    "    \n",
    "    for i in tqdm(range(len(jpeg_files))):\n",
    "\n",
    "        image_stem = jpeg_files[i].split('/')[-1].split('.')[0]\n",
    "\n",
    "        bgr_img = cv2.imread(osp.join(root_path, jpeg_files[i]))\n",
    "        imgc = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # resize image\n",
    "        width = int(imgc.shape[1] * scale_percent / 100)\n",
    "        height = int(imgc.shape[0] * scale_percent / 100)\n",
    "        imgc = cv2.resize(imgc, (width, height)) \n",
    "\n",
    "        nchw_tensor = img_to_nchw_tensor(imgc, device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = sig(net(nchw_tensor)['out']) # remove 'out' for vanilla FCN\n",
    "        pred_np = pred.detach().cpu().numpy().squeeze()\n",
    "        \n",
    "        csvwriter.writerow([image_stem, pred_np.round().sum(), np.prod(imgc.shape[:2])])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "task_3_evaluate_checkpoint_in_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
