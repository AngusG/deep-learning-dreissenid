{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "#import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "import transforms as T\n",
    "#from torchvision import transforms\n",
    "\n",
    "#from torchvision.models import segmentation as models\n",
    "\n",
    "from sklearn.metrics import jaccard_similarity_score as jsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from task_3_utils import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('Found GPU ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torchvision.models.segmentation import fcn_resnet50\n",
    "#net = fcn_resnet50(num_classes=1).cuda()\n",
    "#net = models.__dict__['deeplabv3_resnet50'](num_classes=1, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resume = '/scratch/gallowaa/cciw/logs/v0.1.0/checkpoint/fcn_resnet50_bs40_wd5e-04_aug1_1.ckpt'\n",
    "\n",
    "#root = '/scratch/gallowaa/cciw/logs/v0.2.4/checkpoint'\n",
    "#ckpt_file = 'fcn_resnet50_bs40_wd5e-04_def_1.ckpt'\n",
    "\n",
    "root = '/scratch/gallowaa/cciw/logs/Lab/v1-36-img/checkpoint'\n",
    "ckpt_file = 'unet_bn_bs32_wd5e-04_pytorch_unet_v4_bi_1.ckpt'\n",
    "\n",
    "print('==> Resuming from checkpoint..')\n",
    "checkpoint = torch.load(os.path.join(root, ckpt_file))\n",
    "net = checkpoint['net']\n",
    "best_acc = checkpoint['loss']\n",
    "start_epoch = checkpoint['epoch'] + 1\n",
    "torch.set_rng_state(checkpoint['rng_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = models.__dict__['fcn_resnet50'](num_classes=1)\n",
    "#net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet import UNet\n",
    "#bilinear = True if args.bilinear else False\n",
    "net = UNet(n_channels=3, n_classes=1, bilinear=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))\n",
    "print(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_file = 'GLNI_1356-3_2017-08-15_image-1_crop.jpg'\n",
    "#test_file = 'GLNI_1352-1_2017-08-16_image-1_crop.jpg'\n",
    "#test_file = 'GLNI_1346-2_2017-08-17_image-1_crop.jpg'\n",
    "#root_path = '/scratch/ssd/gallowaa/cciw/dataset_raw_v0-2-x/Train/2017-08/'\n",
    "root_path = '/scratch/ssd/gallowaa/cciw/dataset_raw/Test/Lab/done/'\n",
    "\n",
    "#img = cv2.imread(os.path.join(root_path, test_file))\n",
    "#img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss() # sigmoid cross entropy\n",
    "\n",
    "mytforms = []\n",
    "mytforms.append(T.RandomCrop(224))\n",
    "mytforms.append(T.RandomHorizontalFlip(0.5))\n",
    "mytforms.append(T.RandomVerticalFlip(0.5))\n",
    "mytforms.append(T.ToTensor())\n",
    "mytforms.append(T.Normalize((0.2613, 0.2528, 0.2255), \n",
    "                            (0.2637, 0.2546, 0.2306))) \n",
    "mytforms = T.Compose(mytforms)\n",
    "\n",
    "test_tform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.2613, 0.2528, 0.2255), # mean (RGB)\n",
    "                (0.2637, 0.2546, 0.2306))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for debugging purposes\n",
    "trainset = datasets.VOCSegmentation(\n",
    "    root='/scratch/ssd/gallowaa/cciw/Lab', year='2012', \n",
    "    image_set='train', download=False,\n",
    "    transforms=mytforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for debugging purposes\n",
    "valset = datasets.VOCSegmentation(\n",
    "    root='/scratch/ssd/gallowaa/cciw/Lab', year='2012', \n",
    "    image_set='val', download=False,\n",
    "    transforms=test_tform)\n",
    "    \n",
    "bs = 75\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from task_3_utils import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_iou, val_loss = evaluate(net, valloader, loss_fn, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([[0, 0, 0],\n",
    "                   [1, 1, 0]])\n",
    "\n",
    "y_pred = np.array([[1, 1, 1],\n",
    "                   [1, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsc(y_true[0], y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_np.round()[:, 0].reshape(pred_np.shape[0], -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_np.reshape(targets_np.shape[0], -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_iou = 0\n",
    "running_loss = 0\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, targets) in enumerate(valloader):\n",
    "        targets_np = targets.numpy()\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        pred = sig(net(inputs))\n",
    "\n",
    "        # dataloader outputs targets with shape NHW, but we need NCHW\n",
    "        batch_loss = loss_fn(pred, targets.unsqueeze(dim=1).float())\n",
    "        running_loss += batch_loss.item()\n",
    "\n",
    "        # jaccard similarity (IoU) on CPU\n",
    "        pred_np = pred.detach().cpu().numpy()\n",
    "        print(i, pred_np.shape)\n",
    "        print(i, targets_np.shape)\n",
    "\n",
    "        # flatten predictions and targets for IoU calculation\n",
    "        running_iou += jsc(\n",
    "            pred_np.round()[:, 0].reshape(pred_np.shape[0], -1),\n",
    "        targets_np.reshape(targets_np.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.argmax(pred_np, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ct = 0\n",
    "mean_iou = 0\n",
    "with torch.no_grad():    \n",
    "    for batch, (inputs, targets) in enumerate(valloader):\n",
    "        inputs = inputs.cuda()\n",
    "        targets_np = targets.detach().cpu().numpy()\n",
    "        pred = sig(net(inputs))\n",
    "        pred_np = pred.detach().cpu().numpy()       \n",
    "        lbl = targets_np.reshape(targets_np.shape[0], -1)\n",
    "        out = pred_np.round()[:, 0].reshape(pred_np.shape[0], -1)\n",
    "        iou = jsc(out, lbl)\n",
    "        mean_iou += iou\n",
    "        #print(batch, iou)\n",
    "mean_iou /= len(valloader)\n",
    "print('%.4f' % mean_iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.time()-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "#files = os.listdir(root_path)\n",
    "files = glob.glob(root_path + '*.jpg')\n",
    "\n",
    "w = 224\n",
    "sy = 275\n",
    "sx = 1050\n",
    "plt.imshow(img[sy:sy + w, sx:sx + w, :])\n",
    "\n",
    "#for i in range(3):\n",
    "i = 2\n",
    "img = cv2.imread(os.path.join(root_path, files[i]))\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "imgc = img[sy:sy + w, sx:sx + w, :]\n",
    "imgt = torch.FloatTensor(imgc).to(device)\n",
    "imgt = imgt / imgt.max()\n",
    "imgt = imgt.unsqueeze(0)\n",
    "inputs_nchw = imgt.permute(0, 3, 1, 2)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = sig(net(inputs_nchw))\n",
    "inputs_nhwc = inputs_nchw.permute(0, 2, 3, 1)\n",
    "\n",
    "idx = 0\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))\n",
    "ax1.imshow(inputs_nhwc.detach().cpu().numpy()[idx])\n",
    "ax2.imshow(pred.detach().cpu().numpy()[idx, 0])\n",
    "ax3.imshow(inputs_nhwc.detach().cpu().numpy()[idx], alpha=0.75)\n",
    "ax3.imshow(pred.detach().cpu().numpy()[idx, 0], alpha=0.5)\n",
    "ax1.axis('off')\n",
    "ax2.axis('off')\n",
    "ax3.axis('off')\n",
    "plt.tight_layout()\n",
    "#fig.savefig('img/' + ckpt_file.split('.')[0] + '_' + files[i].split('.')[0] + '_full.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valloader) * 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pred = sig(net(inputs))\n",
    "\n",
    "inputs_nhwc = inputs.permute(0, 2, 3, 1)\n",
    "inputs_nhwc_np = inputs_nhwc.detach().cpu().numpy()    \n",
    "pred_np = pred.detach().cpu().numpy()\n",
    "targets_np = targets.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_binary_iou(outputs, targets, eps=1e-6):\n",
    "    \"\"\"Returns the average binary intersection-over-union score.\n",
    "    Similar to sklearn.metrics.jaccard_similarity_score.\n",
    "    @param outputs are model predictions (post-sigmoid) in Nx1xHxW format.\n",
    "    @param targets are the labels in NxHxW format.\n",
    "    @param eps is a small constant to prevent division by zero.\n",
    "    \"\"\"\n",
    "    outputs = outputs.squeeze(1).round().long()\n",
    "    # zero if output=0 or pred=0\n",
    "    intersection = (outputs & targets).float().sum((1, 2))\n",
    "    union = (outputs | targets).float().sum((1, 2))\n",
    "    iou = intersection / (union + eps)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_binary_iou(pred, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl = targets_np.reshape(bs, -1)\n",
    "out = pred_np.round()[:, 0].reshape(bs, -1)\n",
    "jscv = jsc(out, lbl)\n",
    "print(jscv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydensecrf.densecrf as dcrf\n",
    "import pydensecrf.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.unary_from_softmax?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_crf(inputs_nhwc_np, pred_np, idx):\n",
    "    MAX_ITER = 10\n",
    "    labels = np.stack([pred_np[idx, 0], 1 - pred_np[idx, 0]])\n",
    "    c, h, w = labels.shape[0], labels.shape[1], labels.shape[2]\n",
    "    labels = labels.astype('float') / labels.max()\n",
    "    U = utils.unary_from_softmax(labels)\n",
    "    U = np.ascontiguousarray(U)\n",
    "    d = dcrf.DenseCRF2D(w, h, c)\n",
    "    d.setUnaryEnergy(U)\n",
    "    \"\"\"\n",
    "    @param compat=3, Potts model - it introduces a penalty for nearby similar \n",
    "    pixels that are assigned different labels. \n",
    "    \"\"\"\n",
    "    # This adds the color-independent term, features are the locations only.\n",
    "    d.addPairwiseGaussian(sxy=3, compat=3)\n",
    "    # This adds the color-dependent term, i.e. features are (x,y,r,g,b).\n",
    "    # im is an image-array, e.g. im.dtype == np.uint8\n",
    "\n",
    "    mean = (0.2613, 0.2528, 0.2255), # mean (RGB)\n",
    "    std  = (0.2637, 0.2546, 0.2306)\n",
    "    image = (((inputs_nhwc_np[idx] * std) + mean) * 255).astype('uint8')\n",
    "\n",
    "    d.addPairwiseBilateral(sxy=80, srgb=13, rgbim=image, compat=10)\n",
    "    Q = d.inference(MAX_ITER)\n",
    "    Q = np.array(Q).reshape((c, h, w))\n",
    "    # binarize output\n",
    "    Q[0][Q[0] >= 0.5] = 1\n",
    "    Q[0][Q[0] < 0.5] = 0\n",
    "    \n",
    "    return Q[0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = (0.2613, 0.2528, 0.2255), # mean (RGB)\n",
    "std  = (0.2637, 0.2546, 0.2306)\n",
    "image = (((inputs_nhwc_np[idx] * std) + mean) * 255).astype('uint8')\n",
    "print(image.min())\n",
    "print(image.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_np.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Q[0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize=(12, 2.5)\n",
    "#figsize=(6, 3)\n",
    "#idx = 2 # train mode\n",
    "for idx in range(len(pred_np)):\n",
    "    if idx == 0 or idx == 5:\n",
    "        \n",
    "        pred_crf = run_crf(inputs_nhwc_np, pred_np, idx)\n",
    "        \n",
    "        fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5, figsize=figsize)\n",
    "        ax1.imshow(inputs_nhwc_np[idx])\n",
    "        ax2.imshow(pred_np[idx, 0])\n",
    "        ax3.imshow(pred_np.round()[idx, 0])\n",
    "        ax4.imshow(pred_crf)\n",
    "        ax5.imshow(targets_np[idx])\n",
    "        lbl = targets_np[idx].reshape(1, -1)\n",
    "        out = pred_np.round()[idx, 0].reshape(1, -1)\n",
    "        out_crf = pred_crf.reshape(1, -1)\n",
    "        ax1.set_title('Image'); ax2.set_title('Logits') \n",
    "        ax3.set_title('IoU %.2f' % jsc(out, lbl)); \n",
    "        ax4.set_title('IoU %.2f' % jsc(out_crf, lbl))\n",
    "        ax5.set_title('Label')\n",
    "        pretty_image([ax1, ax2, ax3, ax4, ax5])\n",
    "        plt.savefig(ckpt_file.split('/')[-1].split('.')[0] + '_lab_val_demo' + '_%d.png' % idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs, targets in trainloader:\n",
    "    inputs, targets = inputs.cuda(), targets.cuda()\n",
    "    break\n",
    "x = inputs.permute(0, 2, 3, 1)\n",
    "print(x.shape)\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.mean(dim=(0, 1, 2))\n",
    "#p = net(inputs)['out']\n",
    "#p.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.std(dim=(0, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.mean(dim=(1, 2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = pytorch_unet.UNet(1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    net(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "relu = nn.ReLU()\n",
    "image_mean = x.mean(dim=(1, 2, 3), keepdim=True)\n",
    "variance = x**2 - image_mean**2\n",
    "variance = relu(variance)  # this relu is critical for grad wrt x\n",
    "stddev = torch.sqrt(variance)\n",
    "min_stddev = torch.rsqrt(\n",
    "    torch.prod(torch.FloatTensor([x.size()[1:]]))).cuda()\n",
    "pixel_value_scale = torch.max(stddev, min_stddev)\n",
    "x = x - image_mean\n",
    "#x = x / pixel_value_scale\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "img = x.detach().cpu().numpy()[idx]\n",
    "\n",
    "ax1.imshow(img)\n",
    "#ax2.imshow(targets.detach().cpu().numpy()[idx])\n",
    "#ax2.imshow(variance[idx].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.mean(dim=(1, 2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 10\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_targets = torch.zeros((targets.size(0), targets.size(1), targets.size(2)))\n",
    "print(val_targets.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_targets.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_iou = 0\n",
    "val_loss = 0\n",
    "for inputs, targets in valloader:\n",
    "    inputs, targets = inputs.cuda(), targets.cuda()\n",
    "    val_targets = torch.zeros(\n",
    "        (targets.size(0), targets.size(1), targets.size(2)), \n",
    "        dtype=torch.long).cuda()\n",
    "    val_targets[targets[:, :, :, 0] == 128] = 1\n",
    "    with torch.no_grad():\n",
    "        pred = net(inputs)['out'] # fprop\n",
    "        batch_iou = eval_binary_iou(sig(pred), val_targets)\n",
    "        val_iou += batch_iou.item()\n",
    "        # dataloader outputs targets with shape NHW, but we need NCHW\n",
    "        val_targets = val_targets.unsqueeze(dim=1).float()\n",
    "        batch_loss = loss_fn(pred, val_targets)\n",
    "        val_loss += batch_loss.item()\n",
    "        print(batch_iou)\n",
    "val_loss /= len(valloader)\n",
    "val_iou /= len(valloader)\n",
    "print('Loss: {:.4f}, IoU: {:.4f}'.format(val_loss, val_iou))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_fn(pred, targets.unsqueeze(1).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.unique(targets.detach().cpu().numpy()[1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(pred.detach().cpu().numpy().reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = pred.squeeze(1).round().long()\n",
    "#outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#figsize=(9, 3)\n",
    "#figsize=(6, 3)\n",
    "#idx = 2 # train mode\n",
    "for idx in range(bs):\n",
    "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4)\n",
    "    ax1.imshow(inputs_nhwc.detach().cpu().numpy()[idx])\n",
    "    ax2.imshow(pred.detach().cpu().numpy()[idx, 0])\n",
    "    ax3.imshow(pred.round().detach().cpu().numpy()[idx, 0])\n",
    "    #ax3.imshow(union.detach().cpu().numpy()[idx])\n",
    "    ax4.imshow(targets.detach().cpu().numpy()[idx])\n",
    "    \n",
    "    #lbl = targets[idx].cpu().numpy().reshape(1, -1)\n",
    "    #out = outputs[idx].cpu().numpy().reshape(1, -1)\n",
    "    #jscv = jsc(out, lbl)\n",
    "\n",
    "    #ax1.set_title('Image'); ax2.set_title('Logits') \n",
    "    #ax3.set_title('IoU %.2f' % iou[idx]); \n",
    "    #ax4.set_title('IoU %.2f' % jscv)\n",
    "    pretty_image([ax1, ax2, ax3, ax4])\n",
    "    #plt.savefig(resume.split('/')[-1].split('.')[0] + '_demo_preds_train' + str(net.training) + '_%d.png' % idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputs.round().int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero if output=0 or pred=0\n",
    "outputs = pred.squeeze(1).round().long()\n",
    "eps = 1e-6\n",
    "intersection = (outputs & targets).float().sum((1, 2))\n",
    "print(intersection)\n",
    "union = (outputs | targets).float().sum((1, 2))\n",
    "print(union)\n",
    "iou = intersection / (union + eps)\n",
    "print(iou.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intersection = torch.m(outputs == targets).float().sum((1, 2))\n",
    "#print(intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iou.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 0.20.2\n",
    "from sklearn.metrics import jaccard_similarity_score as jsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsc(np.array([1, 1]), np.array([1, 1]))\n",
    "jsc(np.array([1, 1]), np.array([1, 0]))\n",
    "jsc(np.array([1, 1, 0]), np.array([1, 0, 0]))\n",
    "jsc(np.array([[1, 1, 0]]), np.array([[1, 0, 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "lbl = targets[0].cpu().numpy().reshape(1, -1)\n",
    "out = outputs[0].cpu().numpy().reshape(1, -1)\n",
    "jscv = jsc(out, lbl)\n",
    "print(jscv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_intersection = torch.mul(pred.squeeze(1), targets.squeeze(1)).sum((1, 2))\n",
    "print(soft_intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_union = (pred.squeeze(1) + targets.squeeze(1)).sum((1, 2)) - soft_intersection\n",
    "soft_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(soft_intersection / soft_union).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_np = iou.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs_nhwc = inputs.permute(0, 2, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_image(axes):\n",
    "    for ax in axes:\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_group in optimizer.param_groups:\n",
    "    print(param_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_group['lr'] = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    for batch, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        pred = net(inputs)['out']\n",
    "        \n",
    "        loss = loss_fn(pred, \n",
    "                       torch.LongTensor(\n",
    "                           targets.unsqueeze(1) * 255)\n",
    "                      )\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'\n",
    "          .format(epoch + 1, epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pixel_acc(targets, targets)\n",
    "pixel_acc(pred, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_acc(pred, label):\n",
    "    #_, preds = torch.max(pred, dim=1)\n",
    "    preds = torch.argmax(pred, dim=1)\n",
    "    valid = (label >= 0).long()\n",
    "    acc_sum = torch.sum(valid * (preds == label).long())\n",
    "    pixel_sum = torch.sum(valid)\n",
    "    acc = acc_sum.float() / (pixel_sum.float() + 1e-10)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationModuleBase(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SegmentationModuleBase, self).__init__()\n",
    "\n",
    "    def pixel_acc(self, pred, label):\n",
    "        _, preds = torch.max(pred, dim=1)\n",
    "        valid = (label >= 0).long()\n",
    "        acc_sum = torch.sum(valid * (preds == label).long())\n",
    "        pixel_sum = torch.sum(valid)\n",
    "        acc = acc_sum.float() / (pixel_sum.float() + 1e-10)\n",
    "        return acc\n",
    "\n",
    "\n",
    "class SegmentationModule(SegmentationModuleBase):\n",
    "    def __init__(self, net_enc, net_dec, crit, deep_sup_scale=None):\n",
    "        super(SegmentationModule, self).__init__()\n",
    "        self.encoder = net_enc\n",
    "        self.decoder = net_dec\n",
    "        self.crit = crit\n",
    "        self.deep_sup_scale = deep_sup_scale\n",
    "\n",
    "    def forward(self, feed_dict, *, segSize=None):\n",
    "        # training\n",
    "        if segSize is None:\n",
    "            if self.deep_sup_scale is not None: # use deep supervision technique\n",
    "                (pred, pred_deepsup) = self.decoder(self.encoder(feed_dict['img_data'], return_feature_maps=True))\n",
    "            else:\n",
    "                pred = self.decoder(self.encoder(feed_dict['img_data'], return_feature_maps=True))\n",
    "\n",
    "            loss = self.crit(pred, feed_dict['seg_label'])\n",
    "            if self.deep_sup_scale is not None:\n",
    "                loss_deepsup = self.crit(pred_deepsup, feed_dict['seg_label'])\n",
    "                loss = loss + loss_deepsup * self.deep_sup_scale\n",
    "\n",
    "            acc = self.pixel_acc(pred, feed_dict['seg_label'])\n",
    "            return loss, acc\n",
    "        # inference\n",
    "        else:\n",
    "            pred = self.decoder(self.encoder(feed_dict['img_data'], return_feature_maps=True), segSize=segSize)\n",
    "            return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
