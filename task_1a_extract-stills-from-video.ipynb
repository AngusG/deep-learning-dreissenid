{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from glob import glob\n",
    "from utils import draw_lines\n",
    "\n",
    "# https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "figsize = (8, 6)\n",
    "save_figures = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = '/scratch/ssd/cciw/Videos-20200114T160100Z-001/Quad1'\n",
    "#file = 'GLNI_12-1_2016-07-11_video-1.mp4'\n",
    "file = 'GLNI_456-3_2015-07-17_video-1.mp4'\n",
    "#outpath = file.split('.')[0]\n",
    "#f = os.path.join(path, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = r'/scratch/gallowaa/cciw/Data'\n",
    "\n",
    "# Search for all video files on Google Drive...\n",
    "all_videos = glob(os.path.join(DATA_PATH, 'Videos_and_stills/GLNI/*/*/*/Videos/Quad*/*.mp4'))\n",
    "videotable_path = os.path.join(DATA_PATH, 'Tables', 'QuadratVideos.csv')\n",
    "video_df = pd.read_csv(videotable_path, index_col=0)\n",
    "\n",
    "vpath = video_df.iloc[video_df[video_df['Name'] == file].index]['Quadrat Video Path']\n",
    "tokens = video_df[video_df['Name'] == file]['Quadrat Video Path'].values[0].split('\\\\')\n",
    "#print(tokens)\n",
    "\n",
    "video_path = DATA_PATH + '/Videos_and_stills/GLNI'\n",
    "for tok in tokens[4:-1]:\n",
    "    video_path += '/' + tok\n",
    "video_path = os.path.join(video_path, file)\n",
    "print('Loading video: ', video_path)\n",
    "\n",
    "'''\n",
    "out_path = os.path.join(video_path, 'data')\n",
    "if not os.path.exists(out_path):\n",
    "    os.mkdir(out_path)\n",
    "    print('Making dir ', out_path)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @param rho Distance resolution of the accumulator (pixels).\n",
    "rho = 1  \n",
    "# @param theta Angle resolution of the accumulator (radians).\n",
    "theta = np.pi / 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video_path) #cap.set(cv2.CAP_PROP_FPS, FPS)\n",
    "sz = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "      int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "print(sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read first frame\n",
    "ret, im = cap.read() \n",
    "\n",
    "if sz[0] == 1440:\n",
    "    x_trim, y_trim = 1, 145\n",
    "    canny_thresh1, canny_thresh2 = 60, 300\n",
    "    \"\"\"@param threshold Accumulator threshold, return \n",
    "    lines with more than threshold of votes. (intersection points)\"\"\"\n",
    "    threshold = 125\n",
    "    \"\"\"@param minLineLength Minimum line length. \n",
    "    Line segments shorter than that are rejected. (pixels)\"\"\"\n",
    "    mLL = 400\n",
    "    \"\"\"@param maxLineGap Maximum allowed gap between points \n",
    "    on the same line to link them. (pixels)\"\"\"\n",
    "    mLG = 150\n",
    "    im = im[y_trim:-y_trim, x_trim:-x_trim, :]\n",
    "    crop_frame_border = True\n",
    "else:\n",
    "    canny_thresh1, canny_thresh2 = 30, 300\n",
    "    threshold = 125\n",
    "    mLL = 600\n",
    "    mLG = 250\n",
    "    crop_frame_border = False\n",
    "\n",
    "\"\"\"this method may downsample, so set the video writer \n",
    "resolution to the processed image resolution\"\"\"\n",
    "img, edges = draw_lines(im, rho=rho, theta=theta, mll=mLL, \n",
    "                        mlg=mLG, threshold=threshold, ds=1)    \n",
    "sz = (img.shape[1], img.shape[0])\n",
    "print(sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cap.isOpened():\n",
    "    fps = 20\n",
    "    vout = cv2.VideoWriter()\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    vout.open(file.split('.')[0] + '-quadrat-demo.mp4', fourcc, fps, sz, True)\n",
    "    print('opened stream', sz)\n",
    "else:\n",
    "    print('cap is not open')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentFrame = 0\n",
    "\n",
    "#for i in range(100):\n",
    "while(True):\n",
    "    \n",
    "    # Capture frame-by-frame\n",
    "    ret, im = cap.read()\n",
    "    if not ret: break\n",
    "\n",
    "    '''\n",
    "    # For saving still images\n",
    "    name = 'pframe_pi45_' + str(currentFrame) + '.jpg'\n",
    "    save_path = os.path.join(out_path, name)\n",
    "    print ('Creating...' + name)\n",
    "    '''\n",
    "    \n",
    "    if crop_frame_border:\n",
    "        im = im[y_trim:-y_trim, x_trim:-x_trim, :]\n",
    "    \n",
    "    # Do processing\n",
    "    img, _ = draw_lines(im, rho=rho, theta=theta, mll=mLL, \n",
    "                        mlg=mLG, threshold=threshold, ds=1, \n",
    "                        canny_1=canny_thresh1, canny_2=canny_thresh2)\n",
    "    \n",
    "    \"\"\"Save still image in jpeg format\n",
    "    cv2.imwrite(save_path, img)\"\"\"\n",
    "    \n",
    "    \"\"\"For annotating video\n",
    "    @param org Bottom-left corner of the text string.\n",
    "    @param org Bottom-left corner of the text string in the image.\n",
    "    @param fontFace Font type, see #HersheyFonts.\n",
    "    @param fontScale Font scale factor that is multiplied by the font-specific base size.\n",
    "    @param color Text color.\n",
    "    @param thickness Thickness of the lines used to draw a text.\n",
    "    @param lineType Line type. See #LineTypes\n",
    "    \"\"\"\n",
    "    cv2.putText(                 # x, y\n",
    "        img, str(currentFrame), (50, 50), cv2.FONT_HERSHEY_PLAIN, 2, (0,255,0), 1, cv2.LINE_AA)\n",
    "    vout.write(img)    \n",
    "\n",
    "    # To stop duplicate images\n",
    "    currentFrame += 1\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "vout.release()\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# to seek into a specific frame\n",
    "for _ in range(28):\n",
    "    ret, im = cap.read()\n",
    "\"\"\"    \n",
    "\"\"\"\n",
    "ret, im = cap.read()\n",
    "if ret is not None:\n",
    "    plt.imshow(im)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if crop_frame_border:\n",
    "    im = im[y_trim:-y_trim, x_trim:-x_trim, :]\n",
    "\n",
    "img, edges = draw_lines(im, rho=1, theta=np.pi/45, mll=mLL,\n",
    "                        mlg=mLG, threshold=125, ds=1, \n",
    "                        canny_1=canny_thresh1, canny_2=canny_thresh2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(14, 12))\n",
    "plt.imshow(img)\n",
    "#plt.imshow(im[y_trim:-y_trim, x_trim:-x_trim, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('test.jpg', im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.circle(img, (800, 400), 10, (255, 0, 0), thickness=2, lineType=8, shift=0)\n",
    "plt.figure(figsize=figsize)\n",
    "plt.imshow(img)\n",
    "plt.tight_layout()\n",
    "if save_figures:\n",
    "    plt.savefig('img/' + outpath + '-Step-2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
