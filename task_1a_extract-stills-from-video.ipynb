{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# local libraries\n",
    "from utils import draw_lines\n",
    "\n",
    "%matplotlib inline\n",
    "# https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (8, 6)\n",
    "save_figures = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = '/scratch/ssd/cciw/Videos-20200114T160100Z-001/Quad1'\n",
    "#file = 'GLNI_12-1_2016-07-11_video-1.mp4'\n",
    "file = 'GLNI_456-3_2015-07-17_video-1.mp4'\n",
    "#outpath = file.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = os.path.join(path, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = r'/scratch/gallowaa/cciw/Data'\n",
    "\n",
    "# Search for all video files on Google Drive...\n",
    "all_videos = glob(os.path.join(DATA_PATH, 'Videos_and_stills/GLNI/*/*/*/Videos/Quad*/*.mp4'))\n",
    "\n",
    "videotable_path = os.path.join(DATA_PATH, 'Tables', 'QuadratVideos.csv')\n",
    "video_df = pd.read_csv(videotable_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vpath = video_df.iloc[video_df[video_df['Name'] == file].index]['Quadrat Video Path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = video_df[video_df['Name'] == file]['Quadrat Video Path'].values[0].split('\\\\')\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = DATA_PATH + '/Videos_and_stills/GLNI'\n",
    "for tok in tokens[4:-1]:\n",
    "    video_path += '/' + tok\n",
    "video_path = os.path.join(video_path, file)\n",
    "print(video_path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "out_path = os.path.join(video_path, 'data')\n",
    "\n",
    "if not os.path.exists(out_path):\n",
    "    os.mkdir(out_path)\n",
    "    print('Making dir ', out_path)\n",
    "'''    \n",
    "\n",
    "## some videowriter props\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = (img.shape[1], img.shape[0])\n",
    "print(sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = 20\n",
    "cap = cv2.VideoCapture(video_path) #cap.set(cv2.CAP_PROP_FPS, FPS)\n",
    "sz = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "      int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "print(sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.isOpened()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vout = cv2.VideoWriter()\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "vout.open(file.split('.')[0] + '-quadrat-demo.mp4', fourcc, fps, sz, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentFrame = 0\n",
    "\n",
    "#while(True):\n",
    "for i in range(20):\n",
    "    \n",
    "    # Capture frame-by-frame\n",
    "    ret, im = cap.read()\n",
    "    \n",
    "    if not ret: break\n",
    "\n",
    "    # Saves image of the current frame in jpg file\n",
    "    '''\n",
    "    name = 'pframe_pi45_' + str(currentFrame) + '.jpg'\n",
    "    save_path = os.path.join(out_path, name)\n",
    "    print ('Creating...' + name)\n",
    "    '''\n",
    "    \n",
    "    # Do processing\n",
    "    img = draw_lines(\n",
    "        im, rho=1, theta=np.pi/45, mll=400, mlg=200, threshold=100, ds=1)\n",
    "    \n",
    "    # for saving still images\n",
    "    #cv2.imwrite(save_path, img)\n",
    "    \n",
    "    \"\"\"For annotating video\n",
    "    \n",
    "    @param org Bottom-left corner of the text string.\n",
    "    @param org Bottom-left corner of the text string in the image.\n",
    "    @param fontFace Font type, see #HersheyFonts.\n",
    "    @param fontScale Font scale factor that is multiplied by the font-specific base size.\n",
    "    @param color Text color.\n",
    "    @param thickness Thickness of the lines used to draw a text.\n",
    "    @param lineType Line type. See #LineTypes\n",
    "    \"\"\"\n",
    "    cv2.putText(                 # x, y\n",
    "        img, str(currentFrame), (50, 50), cv2.FONT_HERSHEY_PLAIN, 2, (0,255,0), 1, cv2.LINE_AA)\n",
    "    vout.write(img)    \n",
    "\n",
    "    # To stop duplicate images\n",
    "    currentFrame += 1\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "vout.release()\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    ret, im = cap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, im = cap.read()\n",
    "print(ret)\n",
    "#plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trim = 145\n",
    "x_trim = 1\n",
    "img, edges = draw_lines(\n",
    "    im[y_trim:-y_trim, x_trim:-x_trim, :], rho=1, theta=np.pi/45, mll=400, mlg=200, threshold=50, ds=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(14, 12))\n",
    "plt.imshow(im[y_trim:-y_trim, x_trim:-x_trim, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.circle(img, (800, 400), 10, (255, 0, 0), thickness=2, lineType=8, shift=0)\n",
    "plt.figure(figsize=figsize)\n",
    "plt.imshow(img)\n",
    "plt.tight_layout()\n",
    "if save_figures:\n",
    "    plt.savefig('img/' + outpath + '-Step-2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
