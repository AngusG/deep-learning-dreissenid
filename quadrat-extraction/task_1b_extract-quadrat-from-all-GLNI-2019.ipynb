{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the quadrat from all GLNI images in the dataset\n",
    "\n",
    "This is a preprocessing step for generating predictions on GLNI 2019 data.\n",
    "\n",
    "### To successfully extract a quadrat the algorithm assumes:\n",
    "\n",
    "- All four corners of the quadrat are contained in the image, i.e.~the side lengths or corners are not \n",
    "cropped from the scene.\n",
    "\n",
    "- The quadrat side lengths are not occluded, e.g., by diver equipment, mesh bags, or vegetation.\n",
    "\n",
    "- The image is sufficiently clear, i.e.~not turbulent or cloudy from disrupted sediment.\n",
    "\n",
    "- The camera angle is within $65-90^{\\circ}$ with respect to the top surface of the quadrat.\n",
    "Note that this is separate from quadrat rotation in the camera plane, which can be arbitrary.\n",
    "\n",
    "- The camera is not too far from the quadrat such that the side lengths are less than 400 pixels \n",
    "for $1080 \\times 1440$ resolution, 500 pixels for $1080 \\times 1920$ HD resolution, or 400 for portrait mode in HD res.\n",
    "\n",
    "The algorithm still works reasonably well in some cases even when the assumptions are violated, e.g., input 7 with the mesh bag covering one of the corners, as missing corner coordinates can sometimes be inferred if enough complementary lines are detected. Conversely, even when the assumptions are satisfied, a best effort is made to extract the *interior* of the quadrat, but this occaisionally won't be possible due to missing or misleading lines and part of the quadrat may be included in the output.\n",
    "\n",
    "Prior to running this notebook you must set:\n",
    "\n",
    "1. The `DRAW` variable annotates intermediate results on the image and is nice for visualizing results. It \n",
    "should be set to False for saving the final output.\n",
    "\n",
    "2. The default values for all other parameters can be left as they are.\n",
    "\n",
    "When `DRAW=True`, you will see annotations in the __Post-Processing__ pane.\n",
    "- Large green circles are corner centroids found by K-means\n",
    "- Medium blue circles are all line intersection points after the final stage of processing\n",
    "- Small white circles are proposed crop locations (the quadrat interior corner points)\n",
    "- The X lines corresponding to 'Using X of Y lines' after rejecting outliers and merging similar lines are shown in blue\n",
    "\n",
    "On completion you should have 26 cropped images in the folder `My Drive/Data/Quadrat_Extraction_from_Stills`\n",
    "\n",
    "Dependencies:\n",
    "- `opencv.__version__==4.2.0`\n",
    "- `skimage.__version__==0.16.2` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DRAW = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    DATA_PATH = r'/content/drive/My Drive/Data'\n",
    "    SAVE_PATH = osp.join(DATA_PATH, 'Quadrat_Extraction_from_Stills')\n",
    "    \n",
    "    # cd into current directory so local imports work\n",
    "    %cd '/content/drive/My Drive/cciw-zebra-mussel/quadrat-extraction/'\n",
    "else:\n",
    "    DATA_PATH = osp.join(os.environ['DATA_PATH'], 'cciw/Data')\n",
    "    SAVE_PATH = osp.join(os.environ['DATA_PATH'], 'cciw/Data/Videos_and_stills/TestingSet/GLNI_Quadrats/v4')\n",
    "    \n",
    "print('Reading data from', DATA_PATH)    \n",
    "print('Saving cropped images to', SAVE_PATH)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "from glob import glob\n",
    "\n",
    "# local import\n",
    "from utils import crop_still_image_no_rotate, compute_pairwise_distances\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for all still files in the datset\n",
    "stills = glob(os.path.join(DATA_PATH,'Videos_and_stills/TestingSet/GLNI/*/*/*/*/*/*.jpg'))\n",
    "print('Found %d still images' % len(stills))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices of data in x and y position respectively\n",
    "X, Y = 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_percent = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i = 0\n",
    "#bgr = cv2.imread(stills[i])\n",
    "#plt.imshow(bgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"x_trim and y_trim are used to remove black padding\n",
    "for 1080x1440 video which triggers spurious edges\"\"\"\n",
    "\n",
    "\"\"\"@param canny_thresh initial hysteresis values for Canny edge \n",
    "detector, input to HoughLines\"\"\"\n",
    "\n",
    "\"\"\"@param threshold Accumulator threshold, return \n",
    "lines with more than threshold of votes. (intersection points)\"\"\"\n",
    "threshold = 125\n",
    "\n",
    "\"\"\"@param minLineLength Minimum line length. \n",
    "Line segments shorter than that are rejected. (pixels)\"\"\"\n",
    "\n",
    "\"\"\"@param maxLineGap Maximum allowed gap between points \n",
    "on the same line to link them. (pixels)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mode = 0\n",
    "\n",
    "for i in range(len(stills)):\n",
    "\n",
    "    out_file = stills[i].split('/')[-1].split('.')[0] + '_crop.jpg'\n",
    "    if osp.exists(osp.join(SAVE_PATH, out_file)):\n",
    "        continue\n",
    "\n",
    "    # load the input image\n",
    "    bgr = cv2.imread(stills[i])\n",
    "\n",
    "    # case 1 of 4: small resolution, portrait mode\n",
    "    if bgr.shape[1] == 3788:\n",
    "        print(i, ' case 1 of 4: small resolution, portrait mode')\n",
    "        x_trim, y_trim = 10, 1200\n",
    "        #x_trim, y_trim = 200, 1100\n",
    "        canny_thresh1, canny_thresh2 = 10, 50\n",
    "        mLL, mLG = 400, 200    \n",
    "        mode = 1\n",
    "\n",
    "    # case 2 of 4: small resolution, landscape mode\n",
    "    elif bgr.shape[1] == 6738:\n",
    "        print(i, ' case 2 of 4: small resolution, landscape mode')\n",
    "        x_trim, y_trim = 1000, 1\n",
    "        #x_trim, y_trim = 1100, 200\n",
    "        canny_thresh1, canny_thresh2 = 10, 50\n",
    "        mLL, mLG = 400, 200\n",
    "        mode = 2\n",
    "\n",
    "    # case 3 of 4: large resolution, portrait mode\n",
    "    elif bgr.shape[1] == 4924:\n",
    "        print(i, ' case 3 of 4: large resolution, portrait mode')\n",
    "        x_trim, y_trim = 100, 1100\n",
    "        canny_thresh1, canny_thresh2 = 10, 50\n",
    "        mLL, mLG = 450, 225\n",
    "        mode = 3\n",
    "\n",
    "    # case 4 of 4: large resolution, landscape mode\n",
    "    elif bgr.shape[1] == 7378:\n",
    "        x_trim, y_trim = 1100, 100\n",
    "        print(i, ' case 4 of 4: large resolution, landscape mode')\n",
    "        canny_thresh1, canny_thresh2 = 10, 50\n",
    "        mLL, mLG = 450, 225    \n",
    "        mode = 4\n",
    "\n",
    "    #bgr = bgr[y_trim:-y_trim, x_trim:-x_trim, :]    \n",
    "    width = int(bgr.shape[1] * scale_percent / 100)\n",
    "    height = int(bgr.shape[0] * scale_percent / 100)    \n",
    "    bgr = cv2.resize(bgr, (width, height)) # resize image\n",
    "\n",
    "    '''\n",
    "    plt.close('all')\n",
    "    plt.figure()\n",
    "    plt.imshow(bgr)\n",
    "    plt.title('Input %d' % i, fontsize=24)\n",
    "    plt.show()\n",
    "    '''\n",
    "\n",
    "    start_time = time.time()\n",
    "    bgr, edges, crop = crop_still_image_no_rotate(\n",
    "        bgr, mll=mLL, mlg=mLG, threshold=threshold, canny_1=canny_thresh1, canny_2=canny_thresh2, do_draw=DRAW)\n",
    "    print('Processing took %.2f sec' % float(time.time() - start_time))\n",
    "\n",
    "    '''\n",
    "    plt.figure()\n",
    "    plt.imshow(cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Post-Processing', fontsize=24)\n",
    "    plt.show()\n",
    "    '''\n",
    "\n",
    "    try:\n",
    "        x_start = crop[:, X].min()\n",
    "        x_end = crop[:, X].max()\n",
    "        y_start = crop[:, Y].min()\n",
    "        y_end = crop[:, Y].max()\n",
    "\n",
    "        if (compute_pairwise_distances(crop)[:, 2] < mLL).sum():\n",
    "            print('Corners do not form a square, try to crop based on two clusters')\n",
    "            if mode == 2 or mode == 4:\n",
    "                '''\n",
    "                centroid_y = crop[:, Y].mean()\n",
    "                d_from_y_mean = np.abs(crop[:, Y] - centroid_y)\n",
    "                crop_wrt_y = crop[np.argsort(d_from_y_mean)][:2]       \n",
    "                x_ref = int(crop_wrt_y[:, X].mean())\n",
    "                y_start = crop_wrt_y[:, Y].min()\n",
    "                y_end = crop_wrt_y[:, Y].max()\n",
    "                '''\n",
    "                centroid, crop, cluster_centers = centroid_and_crop_pts_k2means(crop)\n",
    "\n",
    "                # call this x_ref because we don't know if it's left or right\n",
    "                x_ref = int(crop[:, X].mean())\n",
    "                y_start = crop[:, Y].min()\n",
    "                y_end = crop[:, Y].max()\n",
    "                delta = y_end - y_start\n",
    "\n",
    "                if (x_ref + delta) > bgr.shape[1]:\n",
    "                    x_start = x_ref - delta\n",
    "                    x_end = x_ref\n",
    "                else:\n",
    "                    x_end = x_ref + delta\n",
    "                    x_start = x_ref\n",
    "            else:\n",
    "                '''\n",
    "                centroid_x = crop[:, X].mean()\n",
    "                d_from_x_mean = np.abs(crop[:, X] - centroid_x)\n",
    "                crop_wrt_x = crop[np.argsort(d_from_x_mean)][:2]       \n",
    "                y_ref = int(crop_wrt_x[:, Y].mean())\n",
    "                x_start = crop_wrt_x[:, X].min()\n",
    "                x_end = crop_wrt_x[:, X].max()\n",
    "                '''            \n",
    "                centroid, crop, cluster_centers = centroid_and_crop_pts_k2means(crop)\n",
    "                y_ref = int(crop[:, Y].mean())\n",
    "                x_start = crop[:, X].min()\n",
    "                x_end = crop[:, X].max()\n",
    "\n",
    "                # call this y_ref because we don't know if it's top or bottom\n",
    "                delta = x_end - x_start\n",
    "\n",
    "                if (y_ref + delta) > bgr.shape[0]:\n",
    "                    y_start = y_ref - delta\n",
    "                    y_end = y_ref\n",
    "                else:\n",
    "                    y_end = y_ref + delta\n",
    "                    y_start = y_ref\n",
    "\n",
    "        if (y_end - y_start) > mLL and (x_end - x_start) > mLL:\n",
    "            try:\n",
    "                '''\n",
    "                plt.figure()\n",
    "                plt.imshow(bgr[y_start:y_end, x_start:x_end, :])\n",
    "                '''\n",
    "                cv2.imwrite(osp.join(SAVE_PATH, out_file), bgr[y_start:y_end, x_start:x_end, :])\n",
    "                print(i, 'SUCCESS!')\n",
    "            except:\n",
    "                print('Cannot write ', out_file)\n",
    "        else:\n",
    "            print('Corners too close to crop')\n",
    "    except:\n",
    "        print('Cannot crop: insufficient number of corner points found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stills[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(bgr[y_start:y_end, x_start:x_end, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid, crop, cluster_centers = centroid_and_crop_pts_k2means(crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop[:, X].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid_and_crop_pts_k2means(corners):\n",
    "    \"\"\"Use K-means clustering to optimally find the \n",
    "    image centroid and four crop points given \n",
    "    at least four corner points\"\"\"\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=2, random_state=0).fit(corners)\n",
    "    \n",
    "    centroid = kmeans.cluster_centers_.mean(axis=0)\n",
    "    \n",
    "    crop = []\n",
    "    for i in range(2):\n",
    "        cluster = corners[kmeans.labels_ == i]\n",
    "        intra_cluster_d2centroid = np.linalg.norm(cluster - centroid, axis=1)\n",
    "        indices = np.argsort(intra_cluster_d2centroid)\n",
    "        crop.append(cluster[indices][0].astype('int'))\n",
    "    crop = np.asarray(crop)\n",
    "    return centroid, crop, kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_y = crop[:, Y].mean()\n",
    "d_from_y_mean = np.abs(crop[:4, Y] - centroid_y)\n",
    "d_from_y_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_from_y_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_wrt_y = crop[np.argsort(d_from_y_mean)][:2]\n",
    "crop_wrt_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_from_y_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ref + delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bgr.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_from_x_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_from_y_mean = np.abs(crop[:, Y] - centroid_y)\n",
    "d_from_y_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_wrt_y = crop[np.argsort(d_from_y_mean)][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crop_wrt_y\n",
    "x_start = int(crop_wrt_y[:, X].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_start = crop_wrt_y[:, Y].min()\n",
    "y_end = crop_wrt_y[:, Y].max()\n",
    "x_end = x_start + y_end - y_start\n",
    "x_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_pairwise_distances(crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.figure(figsize=(5, 20))\n",
    "plt.imshow(bgr)\n",
    "plt.title('Input %d' % (i + 1), fontsize=24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# to plot all still images\n",
    "for i in range(len(stills)):\n",
    "    bgr = cv2.imread(stills[i])\n",
    "    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "    plt.close('all')\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(bgr[::2, ::2, :])\n",
    "    plt.title(i + 1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(8, 5))\n",
    "#bgr = cv2.imread(stills[i])\n",
    "#rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "ax1.imshow(img)\n",
    "#ax1.imshow(edges)\n",
    "#ax1.set_title('Canny edges', fontsize=16)\n",
    "#ax2.imshow(bgr)\n",
    "#ax2.set_title('Still image with corner points', fontsize=16)\n",
    "ax1.axis('off')\n",
    "#ax2.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#fig.savefig('quatract-extraction-still-%d-step-4.pdf' % i)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
