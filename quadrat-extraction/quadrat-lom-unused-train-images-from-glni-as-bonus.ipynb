{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract quadrats for GLNI samples not used in the training set\n",
    "\n",
    "For the Limnology and Oceanography journal, extract additional training images that we didn't use yet.\n",
    "\n",
    "- There are 921 images in GLNI\n",
    "- Of these, 489 have an analysis ID (i.e., keep only those images with highest suffix). \n",
    "- Of these, 340 were not used in Train v120 (N=152).\n",
    "\n",
    "Note that 489 - 152 = 337, so this suggests that 3 images in train set have the same analysis ID.\n",
    "\n",
    "### To successfully extract a quadrat the algorithm assumes:\n",
    "\n",
    "- All four corners of the quadrat are contained in the image, i.e.~the side lengths or corners are not \n",
    "cropped from the scene.\n",
    "\n",
    "- The quadrat side lengths are not occluded, e.g., by diver equipment, mesh bags, or vegetation.\n",
    "\n",
    "- The image is sufficiently clear, i.e.~not turbulent or cloudy from disrupted sediment.\n",
    "\n",
    "- The camera angle is within $65-90^{\\circ}$ with respect to the top surface of the quadrat.\n",
    "Note that this is separate from quadrat rotation in the camera plane, which can be arbitrary.\n",
    "\n",
    "- The camera is not too far from the quadrat such that the side lengths are less than 400 pixels \n",
    "for $1080 \\times 1440$ resolution, 500 pixels for $1080 \\times 1920$ HD resolution, or 400 for portrait mode in HD res.\n",
    "\n",
    "The algorithm still works reasonably well in some cases even when the assumptions are violated, e.g., input 7 with the mesh bag covering one of the corners, as missing corner coordinates can sometimes be inferred if enough complementary lines are detected. Conversely, even when the assumptions are satisfied, a best effort is made to extract the *interior* of the quadrat, but this occaisionally won't be possible due to missing or misleading lines and part of the quadrat may be included in the output.\n",
    "\n",
    "Prior to running this notebook you must set:\n",
    "\n",
    "1. The `DRAW` variable annotates intermediate results on the image and is nice for visualizing results. It \n",
    "should be set to False for saving the final output.\n",
    "\n",
    "2. The default values for all other parameters can be left as they are.\n",
    "\n",
    "When `DRAW=True`, you will see annotations in the __Post-Processing__ pane.\n",
    "- Large green circles are corner centroids found by K-means\n",
    "- Medium blue circles are all line intersection points after the final stage of processing\n",
    "- Small white circles are proposed crop locations (the quadrat interior corner points)\n",
    "- The X lines corresponding to 'Using X of Y lines' after rejecting outliers and merging similar lines are shown in blue\n",
    "\n",
    "Dependencies:\n",
    "- `opencv.__version__==4.2.0`\n",
    "- `skimage.__version__==0.16.2` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Manual Settings\n",
    "These are the only variables in the notebook user may want to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to draw lines and corners on images, helpful for debugging\n",
    "DRAW = True\n",
    "\n",
    "# to do manual crop based on pixel range that depends only on\n",
    "# resolution and portrait or landscape orientation\n",
    "MANUAL_CROP = False\n",
    "\n",
    "SAVE_PATH_SUBDIR = 'cciw/dataset_raw/quadrat-extraction/glni-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Begin Notebook \n",
    "\n",
    "No need to edit code below this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    DATA_PATH = r'/content/drive/My Drive/Data'\n",
    "    SAVE_PATH = osp.join(DATA_PATH, 'Quadrat_Extraction_from_Stills')\n",
    "\n",
    "    # cd into current directory so local imports work\n",
    "    %cd '/content/drive/My Drive/cciw-zebra-mussel/quadrat-extraction/'\n",
    "else:\n",
    "    DATA_PATH = osp.join(os.environ['DATA_PATH'], 'cciw/Data')\n",
    "    SAVE_PATH = osp.join(os.environ['DATA_PATH'], SAVE_PATH_SUBDIR)\n",
    "    \n",
    "    if not osp.exists(SAVE_PATH):\n",
    "        os.makedirs(SAVE_PATH)\n",
    "\n",
    "print('Reading data from', DATA_PATH)\n",
    "print('Saving cropped images to', SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "from glob import glob\n",
    "\n",
    "# local import\n",
    "from utils import crop_still_image\n",
    "#from utils import crop_still_image_no_rotate\n",
    "from utils import compute_pairwise_distances\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_filename(f):\n",
    "    \"\"\"\n",
    "    :param f: string like '/path/to/filename.jpg'\n",
    "    \n",
    "    returns filename.jpg\n",
    "    \"\"\"\n",
    "    return f.split('/')[-1]\n",
    "\n",
    "def get_uid(f):\n",
    "    \"\"\"\n",
    "    :param f: string like 'GLNI_{PSN}-{QUAD}_{YYY-MM-DD}_image-{SUFFIX}.jpg'\n",
    "    \n",
    "    returns 'GLNI_{PSN}-{QUAD}_{YYY-MM-DD}'\n",
    "    \"\"\"\n",
    "    return f.split('_image')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for all still files in the datset\n",
    "files = glob(osp.join(\n",
    "    DATA_PATH, 'Videos_and_stills/GLNI/*/*/*/Images/*/*.jpg'))\n",
    "print('Found %d still images' % len(files)) # 921\n",
    "\n",
    "# sort the files in decrementing order so that\n",
    "# the next cell only needs to be run once\n",
    "files.sort(reverse=True)\n",
    "# files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep the images with highest suffix number (highest quality),\n",
    "# which correspond to one analysis ID.\n",
    "\n",
    "for i, f in enumerate(files):\n",
    "    # get image suffix\n",
    "    img_nb = int(strip_filename(f).split('.')[0].split('-')[-1])\n",
    "    # check the image number\n",
    "    if img_nb > 1:\n",
    "        # sometimes numbers are non-contiguous\n",
    "        while (img_nb - 1) > 0:\n",
    "            # try to remove the image with decremented suffix\n",
    "            try:\n",
    "                img_path = f.split('GLNI_')[0]\n",
    "                # remove the file\n",
    "                files.remove(osp.join(img_path, get_uid(\n",
    "                    strip_filename(f).split('.')[0]) + '_image-%d.jpg' % (img_nb - 1)))\n",
    "            except:\n",
    "                pass\n",
    "            img_nb -= 1\n",
    "\n",
    "print(len(files)) # 489"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = os.listdir(osp.join(os.environ['DATA_PATH'], 'cciw/VOCdevkit/Train-v120-originals/JPEGImages'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to store train file unique IDs, i.e., the part of the \n",
    "# image name without the '_image-#.jpg'\n",
    "train_uids = []\n",
    "\n",
    "for i in range(len(train_images)):\n",
    "    train_uids.append(get_uid(train_images[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the unused training images in bonus\n",
    "bonus = [f for f in files if get_uid(f.split('/')[-1]) not in train_uids]\n",
    "len(bonus) # 340"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices of data in x and y position respectively\n",
    "X, Y = 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_percent = 25\n",
    "\n",
    "s = (100 // scale_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"x_trim and y_trim are used to remove black padding\n",
    "for 1080x1440 video which triggers spurious edges\"\"\"\n",
    "\n",
    "\"\"\"@param canny_thresh initial hysteresis values for Canny edge \n",
    "detector, input to HoughLines\"\"\"\n",
    "\n",
    "\"\"\"@param threshold Accumulator threshold, return \n",
    "lines with more than threshold of votes. (intersection points)\"\"\"\n",
    "threshold = 125\n",
    "\n",
    "\"\"\"@param minLineLength Minimum line length. \n",
    "Line segments shorter than that are rejected. (pixels)\"\"\"\n",
    "\n",
    "\"\"\"@param maxLineGap Maximum allowed gap between points \n",
    "on the same line to link them. (pixels)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mode = 0\n",
    "for i in range(len(bonus)):\n",
    "\n",
    "    out_file = strip_filename(bonus[i]).split('.')[0] + '_crop.jpg'\n",
    "\n",
    "    if osp.exists(osp.join(SAVE_PATH, out_file)):\n",
    "        pass\n",
    "        #continue\n",
    "\n",
    "    # load the input image\n",
    "    bgr = cv2.imread(bonus[i])\n",
    "    if not MANUAL_CROP:\n",
    "        bgr_orig = bgr.copy()\n",
    "\n",
    "    # case 1 of 4: small resolution, portrait mode\n",
    "    if bgr.shape[1] == 3788:\n",
    "        print(i, ' case 1 of 4: small resolution, portrait mode')\n",
    "        x_trim, y_trim = 100, 1200\n",
    "        #x_trim, y_trim = 200, 1100\n",
    "        canny_thresh1, canny_thresh2 = 10, 50\n",
    "        mLL, mLG = 400, 200    \n",
    "        mode = 1\n",
    "\n",
    "    # case 2 of 4: small resolution, landscape mode\n",
    "    elif bgr.shape[1] == 6738:\n",
    "        print(i, ' case 2 of 4: small resolution, landscape mode')\n",
    "        #x_trim, y_trim = 1000, 1\n",
    "        x_trim, y_trim = 1200, 100\n",
    "        canny_thresh1, canny_thresh2 = 10, 50\n",
    "        mLL, mLG = 400, 200\n",
    "        mode = 2\n",
    "\n",
    "    # case 3 of 4: large resolution, portrait mode\n",
    "    elif bgr.shape[1] == 4924:\n",
    "        print(i, ' case 3 of 4: large resolution, portrait mode')\n",
    "        x_trim, y_trim = 500, 2000\n",
    "        canny_thresh1, canny_thresh2 = 10, 50\n",
    "        mLL, mLG = 450, 225\n",
    "        mode = 3\n",
    "\n",
    "    # case 4 of 4: large resolution, landscape mode\n",
    "    elif bgr.shape[1] == 7378:\n",
    "        #x_trim, y_trim = 1100, 100 # 25% scale\n",
    "        x_trim, y_trim = 2000, 500 # 100% scale\n",
    "        print(i, ' case 4 of 4: large resolution, landscape mode')\n",
    "        canny_thresh1, canny_thresh2 = 10, 50\n",
    "        mLL, mLG = 450, 225    \n",
    "        mode = 4\n",
    "\n",
    "    if MANUAL_CROP:\n",
    "        cv2.imwrite(osp.join(SAVE_PATH, out_file), bgr[y_trim:-y_trim, x_trim:-x_trim, :])\n",
    "    else:\n",
    "        width = int(bgr.shape[1] * scale_percent / 100)\n",
    "        height = int(bgr.shape[0] * scale_percent / 100)    \n",
    "        bgr = cv2.resize(bgr, (width, height)) # resize image\n",
    "\n",
    "        plt.close('all')\n",
    "        plt.figure()\n",
    "        plt.imshow(bgr)\n",
    "        plt.title('Input %d' % i, fontsize=24)\n",
    "        plt.show()\n",
    "\n",
    "        start_time = time.time()\n",
    "        bgr, edges, crop = crop_still_image(\n",
    "            bgr, mll=mLL, mlg=mLG, threshold=threshold, canny_1=canny_thresh1, canny_2=canny_thresh2, do_draw=DRAW)\n",
    "        print('Processing took %.2f sec' % float(time.time() - start_time))\n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB))\n",
    "        plt.title('Post-Processing', fontsize=24)\n",
    "        plt.show()\n",
    "\n",
    "        try:\n",
    "            x_start = crop[:, X].min()\n",
    "            x_end = crop[:, X].max()\n",
    "            y_start = crop[:, Y].min()\n",
    "            y_end = crop[:, Y].max()\n",
    "\n",
    "            if (compute_pairwise_distances(crop)[:, 2] < mLL).sum():\n",
    "                print('Corners do not form a square, try to crop based on two clusters')\n",
    "                if mode == 2 or mode == 4:\n",
    "                    centroid_y = crop[:, Y].mean()\n",
    "                    d_from_y_mean = np.abs(crop[:, Y] - centroid_y)\n",
    "                    crop_wrt_y = crop[np.argsort(d_from_y_mean)][:2]       \n",
    "                    x_ref = int(crop_wrt_y[:, X].mean())\n",
    "                    y_start = crop_wrt_y[:, Y].min()\n",
    "                    y_end = crop_wrt_y[:, Y].max()\n",
    "                    '''\n",
    "                    centroid, crop, cluster_centers = centroid_and_crop_pts_k2means(crop)\n",
    "                    # call this x_ref because we don't know if it's left or right\n",
    "                    x_ref = int(crop[:, X].mean())\n",
    "                    y_start = crop[:, Y].min()\n",
    "                    y_end = crop[:, Y].max()\n",
    "                    '''\n",
    "                    delta = y_end - y_start\n",
    "\n",
    "                    if (x_ref + delta) > bgr.shape[1]:\n",
    "                        x_start = x_ref - delta\n",
    "                        x_end = x_ref\n",
    "                    else:\n",
    "                        x_end = x_ref + delta\n",
    "                        x_start = x_ref\n",
    "                else:\n",
    "                    centroid_x = crop[:, X].mean()\n",
    "                    d_from_x_mean = np.abs(crop[:, X] - centroid_x)\n",
    "                    crop_wrt_x = crop[np.argsort(d_from_x_mean)][:2]       \n",
    "                    y_ref = int(crop_wrt_x[:, Y].mean())\n",
    "                    x_start = crop_wrt_x[:, X].min()\n",
    "                    x_end = crop_wrt_x[:, X].max()\n",
    "                    '''            \n",
    "                    centroid, crop, cluster_centers = centroid_and_crop_pts_k2means(crop)\n",
    "                    y_ref = int(crop[:, Y].mean())\n",
    "                    x_start = crop[:, X].min()\n",
    "                    x_end = crop[:, X].max()\n",
    "                    '''\n",
    "                    # call this y_ref because we don't know if it's top or bottom\n",
    "                    delta = x_end - x_start\n",
    "\n",
    "                    if (y_ref + delta) > bgr.shape[0]:\n",
    "                        y_start = y_ref - delta\n",
    "                        y_end = y_ref\n",
    "                    else:\n",
    "                        y_end = y_ref + delta\n",
    "                        y_start = y_ref\n",
    "\n",
    "            if (y_end - y_start) > mLL and (x_end - x_start) > mLL:\n",
    "                try:\n",
    "                    '''\n",
    "                    plt.figure()\n",
    "                    plt.imshow(bgr[y_start:y_end, x_start:x_end, :])\n",
    "                    '''\n",
    "                    #cv2.imwrite(osp.join(SAVE_PATH, out_file), bgr[y_start:y_end, x_start:x_end, :])\n",
    "\n",
    "                    # write a high res version\n",
    "                    cv2.imwrite(osp.join(SAVE_PATH, out_file), bgr_orig[y_start * s:y_end * s, x_start * s:x_end * s, :])\n",
    "                    print(i, 'SUCCESS!')\n",
    "                except:\n",
    "                    print('Cannot write ', out_file)\n",
    "            else:\n",
    "                print('Corners too close to crop')\n",
    "        except:\n",
    "            print('Cannot crop: insufficient number of corner points found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.imwrite(osp.join(SAVE_PATH, out_file), bgr_orig[y_start * s:y_end * s, x_start * s:x_end * s, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
